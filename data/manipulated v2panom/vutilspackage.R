library(devtools)
use_git()
# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Apply a function to a Data Frame split by year
#'
#' \code{by_year} splits a \code{DataFrame} by a \code{DateVector}
#' grouped by year and applies the supplied function to each element in
#' the resulting \code{list}.
#'
#' @param x \code{DataFrame}
#' @param dates \code{DateVector} that will be grouped by year and
#'              used to split \code{x}.
#' @param fn \code{Function} applied to each group after splitting
#'           \code{x}. The function signature is the corresponding
#'           sub-\code{DataFrame} and sub-\code{DateVector}.
#'
#' @details When splitting \code{x}, \code{by_year} will balance
#'          the groups. This means that if there's an intra-year
#'          change not on January 1st, the last observation in the
#'          previous year will be copied to January 1st. The
#'          rationale is that each group should contain the year's
#'          full codings --- especially since we usually apply the
#'          day-weighted mean function (\code{\link{day_mean}}) to
#'          each group.
#'
#' @examples
#' df <- data.frame(x = 1:3)
#' dates <- as.Date(c("1900-01-01", "1901-02-01", "1901-11-01"))
#' by_year(df, dates, list)
#'
#' @export
by_year <- function(x, dates, fn) {
  .Call('_vutils_by_year', PACKAGE = 'vutils', x, dates, fn)
}

#' @export
day_mean.data.frame <- function(x, dates, na_rm = TRUE) {
  .Call('_vutils_weighted_df_mean', PACKAGE = 'vutils', x, dates, na_rm)
}

#' @export
day_mean.matrix <- function(x, dates, na_rm = TRUE) {
  .Call('_vutils_weighted_matrix_mean', PACKAGE = 'vutils', x, dates, na_rm)
}

#' @export
colMedians.matrix <- function(x) {
  .Call('_vutils_colMedians', PACKAGE = 'vutils', x)
}

#' @export
rowMedians.matrix <- function(x) {
  .Call('_vutils_rowMedians', PACKAGE = 'vutils', x)
}

#' @export
colSDs.matrix <- function(x) {
  .Call('_vutils_colSDs', PACKAGE = 'vutils', x)
}

#' @export
rowSDs.matrix <- function(x) {
  .Call('_vutils_rowSDs', PACKAGE = 'vutils', x)
}

#' @export
locf.default <- function(x) {
  .Call('_vutils_locf_S3vector', PACKAGE = 'vutils', x)
}

#' @export
interpolate.default <- function(x) {
  .Call('_vutils_interpolate_S3vector', PACKAGE = 'vutils', x)
}

#' @export
locf.matrix <- function(x) {
  .Call('_vutils_fill_S3matrix', PACKAGE = 'vutils', x)
}

#' @export
interpolate.matrix <- function(x) {
  .Call('_vutils_interpolate_S3matrix', PACKAGE = 'vutils', x)
}

#' @export
locf.data.frame <- function(x) {
  .Call('_vutils_locf_S3df', PACKAGE = 'vutils', x)
}

#' @export
interpolate.data.frame <- function(x) {
  .Call('_vutils_interpolate_S3df', PACKAGE = 'vutils', x)
}

#' Imprint a matrix! (What does that even mean??)
#'
#' Returns a logical matrix where the elements that are not NA in the
#' columns subsetted by the given logical vector are set as true.
#'
#' @param m A numeric matrix
#' @param v A logical vector the same length as \code{ncol(m)}
#'
#' @export
imprint <- function(m, v) {
  .Call('_vutils_imprint', PACKAGE = 'vutils', m, v)
}

#' Ordinal scale transformation
#'
#' Transforms latent trait estimates into the original ordinal scale.
#'
#' @param z Extracted Z parameter as a matrix
#' @param gamma_mu Extracted gamma_mu as a matrix
#'
#' @return Integer matrix with the same dimensions as our Z matrix
#'
#' @export
ord <- function(z, gamma_mu) {
  .Call('_vutils_ord', PACKAGE = 'vutils', z, gamma_mu)
}

#' Linearized ordinal scale transformation
#'
#' Transforms latent trait estimates into the original interval
#' scale.
#'
#' @param z Extracted \code{Z} parameter as a matrix.
#' @param gamma_mu Extracted \code{gamma_mu} as a matrix.
#'
#' @return Numeric matrix with the same dimensions as our Z matrix.
#' @export
#'
osp <- function(z, gamma_mu) {
  .Call('_vutils_osp', PACKAGE = 'vutils', z, gamma_mu)
}

#' Reduce a numeric matrix
#'
#' Collapses a numeric matrix according to the V-Dem reduction rules.
#'
#' @param m Question specific, wide-formatted matrix
#' @param gaps Logical vector denoting dates (rows) which are gap years
#' @param intra_year Logical vector denoting dates (rows) which are
#'          intra-year observations, (i.e., coded at a month-day date
#'          other than '12-31')
#'
#' @section Warning: For something seemingly so simple, this is the '
#'                   most contentious function at V-Dem. Goodluck.
#'
#'                   Ensure that the matrix is ordered descending by
#'                   date and that the order matches \code{gaps} and
#'                   \code{intra_year}
#'
#' @details \code{reduce} was written to collapse V-Dem style
#'           wide-formatted matrices where the matrix represents a
#'           single question with each coder as a separate column and
#'           each row denoting a country-date. Furthermore, it assumes
#'           that the matrix is a single country subset, is ordered
#'           descending by date, and for simplicity that all missing
#'           values are represented as NA (see reduce.R for more
#'           context).
#'
#'           Thus, For a given matrix \code{m}, \code{reduce} will collapse
#'           backwards the matrix to the row (date) where there is a
#'           change in value within any column versus the preceding
#'           row (date). Changes do not include missing values; if a
#'           column goes from a numeric value to NA this is not
#'           considered a change. Furthermore, as part of the
#'           collapsing, missing values will be imputed backwards if
#'           there is no change.
#'
#'           Two exceptions: gap dates (nonsequential breaks with the
#'           previous date by more than 1 year) are considered changes,
#'           and thus the boundary is preserved. Then, for intra-year
#'           dates values are first imputed \emph{forwards} before
#'           subjected to the normal collapsing rules (for a full
#'           explanation see doc/MM_prep.md).
#'
#' @export
reduce <- function(m, gaps, intra_year) {
  .Call('_vutils_reduce', PACKAGE = 'vutils', m, gaps, intra_year)
}


#' Country-year aggregation helper functions
#'
#' Collection of helper functions meant to used in conjuction with
#' \code{dplyr::summarise_all} when aggregating column-wise from the
#' country-date to country-year level.
#'
#' @param v Vector of any type.
#'
#' @details When aggregating per year, the base R functions may return
#'     a different type than the original input vector. This will
#'     cause the \code{summarise} family of functions to error
#'     out. The collection of helper functions simply take care of
#'     missingness and \code{NA} as appropriate.
#'
#' @name collect_aggregation
NULL

#' @describeIn collect_aggregation Aggregate by max
#' @export
collect_max <- function(v) {
  if (length(v) == 1)
    return(v)

  # Grab the first element if missing instead of NA, so we don't
  # return NA_real_
  if (all(is.na(v))) v[1] else max(v, na.rm = T)
}

#' @describeIn collect_aggregation Aggregate by last
#' @export
collect_last <- function(v) {
  if (length(v) == 1)
    return(v)

  v[v == ""] <- NA

  if (any(!is.na(v)))
    utils::tail(stats::na.omit(v), n = 1)
  else
    v[1]
}

#' @describeIn collect_aggregation Aggregate by first
#' @export
collect_first <- function(v) {
  if (length(v) == 1)
    return(v)

  v[v == ""] <- NA

  if (any(!is.na(v)))
    utils::head(stats::na.omit(v), n = 1)
  else
    v[1]
}



#' @describeIn collect_aggregation Aggregate by mean
#' @export
collect_mean <- function(v) {
  if (inherits(v, "character"))
    stop("cannot take mean of character vector", call. = F)

  if (length(v) == 1)
    return(v)

  if (all(is.na(v))) v[1] else mean(v, na.rm = T)
}

#' Day weighted mean
#'
#' Computes the day weighted arithmetic mean of either a
#' \code{data.frame} or \code{matrix}. The weights are taken from the
#' day difference of the given \code{DateVector} and the mean is
#' calculated column-wise.
#'
#' @param x A \code{data.frame} of numeric/integer columns or a
#'     numeric/integer \code{matrix} object.
#' @param dates Date vector
#' @param na_rm Whether or not to remove NA values when calculating
#'     the mean
#'
#' @examples
#' df <- data.frame(x = c(1, 2, 3), y = c(1L, 2L, 3L))
#' dates <- as.Date(c("1900-01-01", "1900-03-23", "1900-12-31"))
#'
#' day_mean(df, dates)
#'
#' @export
day_mean <- function(x, dates, na_rm = T) UseMethod("day_mean" )

#' @export
day_mean.numeric <- function(x, dates = NULL) {
  day_mean(as.matrix(x), dates = dates)
}

#' @export
day_mean.integer <- function(x, dates = NULL) {
  day_mean(as.matrix(x), dates = dates)
}



#' Year-wise day-weighted aggregation
#'
#' Split-apply-combine style year-wise aggregation from country-date
#' to country-year using the aggregate function \code{\link{day_mean}}.
#'
#' @param x Either a \code{data.frame} or \code{matrix}
#' @param dates \code{DateVector} evaluated within the context of
#'     \code{x} if \code{x} is a \code{data.frame} containing
#'     \code{date.col} as a column. Can also specify "row.names" to
#'     access dates stored as rownames attributes of \code{x}.
#' @param by Additional grouping variables to split \code{x} before
#'     applying the aggregation. Like \code{dates}, if \code{x} is a
#'     \code{data.frame}, then \code{by} will be evaluated within the
#'     context of \code{x}.
#' @param ... Additional arguments passed to
#'     \code{\link[parallel]{mcMap}}.
#'
#' @details \code{to_cy} aggregates from country-date level to
#'     country-year level by splitting the data year-wise based on the
#'     specified \code{DateVector}. The aggregation is done by the
#'     \code{day_mean} function, which takes a day-weighted average.
#'
#' @examples
#' df <- data.frame(historical_date = as.Date(c("1900-01-01", "1900-03-01", "1900-07-11")),
#'                  code = c(1, 2, 1))
#' cy.day_mean(df, historical_date)
#'
#' @export
cy.day_mean <- function(x, dates = NULL, by = NULL, ...) UseMethod("cy.day_mean")

#' @export
cy.day_mean.data.frame <- function(x, dates = NULL, by = NULL, ...) {
  if (!is.data.frame(x))
    x <- as.data.frame(x)

  if (nrow(x) < 1 | ncol(x) == 0) {
    warning("Nothing to aggregate")
    return(x)
  }

  if ("year" %in% colnames(x)) {
    warn("There is already a year column... \n I am dropping it.")
    x$year <- NULL
  }

  prep_arg <- function(arg, e) {
    name <- deparse(arg)
    v <- eval(arg, x, e)

    if (is.null(v))
      return(NULL)

    if (length(v) == 1 && is.character(v) && v == "row.names")
      v <- row.names(x)
    else if (name %in% colnames(x)) {
      x <<- x[, colnames(x) != name, drop = F]
    }

    v
  }

  if (missing(dates))
    stop("Missing dates argument", call. = F)

  # Save the parent.frame to pass as the enclos env for `prep_arg`
  # so we can find objects not residing within `x`
  p <- parent.frame()

  dates_v <- prep_arg(substitute(dates), p) %>% as.Date
  if (length(dates_v) != nrow(x))
    stop("Mismatch length between dates and x", call. = F)

  if (missing(by)) {
    aggregated.df <- by_year(x, dates_v, day_mean) %>%
      do.call(rbind, .)

    return(aggregated.df)
  }

  by_v <- prep_arg(substitute(by), p)
  if (length(by_v) != nrow(x))
    stop("Mismatched length between `by` and x", call. = F)

  dates.ll <- split(dates_v, by_v)
  ll <- split(x, by_v) %>%
    parallel::mcMap(function(sub.df, sub_dates) {
      by_year(sub.df, sub_dates, day_mean) %>%
        do.call(rbind, .)
    }, ., dates.ll, ...)

  mc_assert(ll)
  aggregated.df <- do.call(rbind, ll)

  bynames <- sub("[.]\\d*$", "", row.names(aggregated.df))
  aggregated.df[[deparse(substitute(by))]] <- bynames
  row.names(aggregated.df) <- NULL

  # These next lines seems useless, but otherwise there is a bug in numeric values
  # being slightly different from integer values (e.g. 29.000001 vs. 29) and would not match.
  # This is a problem passed from C++ using Rcpp.
  if ("country_id" %in% names(aggregated.df) & class(aggregated.df$country_id) == "numeric") {
    aggregated.df[["country_id"]] <- as.numeric(as.integer(aggregated.df[["country_id"]]))
  }

  aggregated.df
}

#' @export
clean_by_utable <- function(x, utable, party = FALSE) {UseMethod("clean_by_utable")}

#' @export
clean_by_utable.default <- function(x, utable, party = FALSE) {
  stop("No defined method for this object!")
}

#' @export
clean_by_utable.data.frame <- function(x, utable, party = FALSE) {
  stopifnot(c("year", "country_id") %in% names(x))
  stopifnot(!any(is.na(x$year)))
  stopifnot(!any(is.na(x$country_id)))
  dplyr::inner_join(x, utable[, "country_id", "year"],
                    by = c("country_id", "year")) %>%
    # This may remove tibble grouping, be careful!
    as.data.frame(stringsAsFactors = FALSE)
}

#' @export
clean_by_utable.matrix <- function(x, utable, party = FALSE) {
  assert_str(x, party)
  df <- data.frame(
    country_text_id = get_text_id(x, party),
    historical_date = get_date(x, party) %>%
      to_year %>%
      paste0("-12-31"),
    stringsAsFactors = FALSE) %>%
    dplyr::left_join(
      dplyr::select(utable, country_text_id,
                    historical_date, project),
      by = c("country_text_id", "historical_date"))
  bool <- !is.na(df$project)
  x[bool, ]
}


#' @export
remove_observations <- function(df, remove_bool) {
  stopifnot(!anyNA(remove_bool))
  dirt <- df[remove_bool, ]
  # print_function(dirt)
  list(clean = df[!remove_bool, ], dirty = dirt)
}

#' @export
remove_nonc_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("A*", "A", "A,C", "B", "D")))
    return(list(clean = df, dirty = data.frame()))
  keep_nonc <- df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names), .keep_all = T) %$% id
  remove_nonc <-
    df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::filter(!id %in% keep_nonc) %>%
    pull(id)
  remove_observations(df, df$id %in% remove_nonc)
}

#' @export
remove_c_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("C")))
    return(list(clean = df, dirty = data.frame()))
  stopifnot(length(unique(df$id)) == nrow(df))
  keep_c <-
    df %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names),
                    .keep_all = T) %>%
    pull(id)
  remove_c <-
    df %>%
    dplyr::filter(!id %in% keep_c) %>%
    pull(id)
  out <- remove_observations(df, df$id %in% remove_c)
  stopifnot(no_duplicates(out$clean, col_names))
  return(out)
}

#' @export
remove_ms_duplicates <- function(df) {
  keep_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::arrange(dplyr::desc(id)) %>%
    dplyr::distinct(question_id, country_id, coder_id, historical_date, code,
                    .keep_all = T) %$% id
  remove_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::filter(!id %in% keep_ms) %$% id
  remove_observations(df, df$id %in% remove_ms)
}

#' @export
print_by_name <- function(df) {
  df %>%
    dplyr::group_by(name, class) %>%
    dplyr::summarize(n = n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country <- function(df) {
  df %>%
    dplyr::group_by(country_name) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country_year <- function(df) {
  df %>%
    dplyr::group_by(country_name, year) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(country_name, year) %>%
    as.data.frame(stringsAsFactors = F) %T>%
    print
}

#' @export
clean_by_utable <- function(x, utable, party = FALSE) {UseMethod("clean_by_utable")}

#' @export
clean_by_utable.default <- function(x, utable, party = FALSE) {
  stop("No defined method for this object!")
}

#' @export
clean_by_utable.data.frame <- function(x, utable, party = FALSE) {
  stopifnot(c("year", "country_id") %in% names(x))
  stopifnot(!any(is.na(x$year)))
  stopifnot(!any(is.na(x$country_id)))
  dplyr::inner_join(x, utable[, "country_id", "year"],
                    by = c("country_id", "year")) %>%
    # This may remove tibble grouping, be careful!
    as.data.frame(stringsAsFactors = FALSE)
}

#' @export
clean_by_utable.matrix <- function(x, utable, party = FALSE) {
  assert_str(x, party)
  df <- data.frame(
    country_text_id = get_text_id(x, party),
    historical_date = get_date(x, party) %>%
      to_year %>%
      paste0("-12-31"),
    stringsAsFactors = FALSE) %>%
    dplyr::left_join(
      dplyr::select(utable, country_text_id,
                    historical_date, project),
      by = c("country_text_id", "historical_date"))
  bool <- !is.na(df$project)
  x[bool, ]
}


#' @export
remove_observations <- function(df, remove_bool) {
  stopifnot(!anyNA(remove_bool))
  dirt <- df[remove_bool, ]
  # print_function(dirt)
  list(clean = df[!remove_bool, ], dirty = dirt)
}

#' @export
remove_nonc_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("A*", "A", "A,C", "B", "D")))
    return(list(clean = df, dirty = data.frame()))
  keep_nonc <- df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names), .keep_all = T) %$% id
  remove_nonc <-
    df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::filter(!id %in% keep_nonc) %>%
    pull(id)
  remove_observations(df, df$id %in% remove_nonc)
}

#' @export
remove_c_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("C")))
    return(list(clean = df, dirty = data.frame()))
  stopifnot(length(unique(df$id)) == nrow(df))
  keep_c <-
    df %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names),
                    .keep_all = T) %>%
    pull(id)
  remove_c <-
    df %>%
    dplyr::filter(!id %in% keep_c) %>%
    pull(id)
  out <- remove_observations(df, df$id %in% remove_c)
  stopifnot(no_duplicates(out$clean, col_names))
  return(out)
}

#' @export
remove_ms_duplicates <- function(df) {
  keep_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::arrange(dplyr::desc(id)) %>%
    dplyr::distinct(question_id, country_id, coder_id, historical_date, code,
                    .keep_all = T) %$% id
  remove_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::filter(!id %in% keep_ms) %$% id
  remove_observations(df, df$id %in% remove_ms)
}

#' @export
print_by_name <- function(df) {
  df %>%
    dplyr::group_by(name, class) %>%
    dplyr::summarize(n = n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country <- function(df) {
  df %>%
    dplyr::group_by(country_name) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country_year <- function(df) {
  df %>%
    dplyr::group_by(country_name, year) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(country_name, year) %>%
    as.data.frame(stringsAsFactors = F) %T>%
    print
}

#' @export
clean_by_utable <- function(x, utable, party = FALSE) {UseMethod("clean_by_utable")}

#' @export
clean_by_utable.default <- function(x, utable, party = FALSE) {
  stop("No defined method for this object!")
}

#' @export
clean_by_utable.data.frame <- function(x, utable, party = FALSE) {
  stopifnot(c("year", "country_id") %in% names(x))
  stopifnot(!any(is.na(x$year)))
  stopifnot(!any(is.na(x$country_id)))
  dplyr::inner_join(x, utable[, "country_id", "year"],
                    by = c("country_id", "year")) %>%
    # This may remove tibble grouping, be careful!
    as.data.frame(stringsAsFactors = FALSE)
}

#' @export
clean_by_utable.matrix <- function(x, utable, party = FALSE) {
  assert_str(x, party)
  df <- data.frame(
    country_text_id = get_text_id(x, party),
    historical_date = get_date(x, party) %>%
      to_year %>%
      paste0("-12-31"),
    stringsAsFactors = FALSE) %>%
    dplyr::left_join(
      dplyr::select(utable, country_text_id,
                    historical_date, project),
      by = c("country_text_id", "historical_date"))
  bool <- !is.na(df$project)
  x[bool, ]
}


#' @export
remove_observations <- function(df, remove_bool) {
  stopifnot(!anyNA(remove_bool))
  dirt <- df[remove_bool, ]
  # print_function(dirt)
  list(clean = df[!remove_bool, ], dirty = dirt)
}

#' @export
remove_nonc_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("A*", "A", "A,C", "B", "D")))
    return(list(clean = df, dirty = data.frame()))
  keep_nonc <- df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names), .keep_all = T) %$% id
  remove_nonc <-
    df %>%
    dplyr::filter(class %in% c("A*", "A", "A,C", "B", "D")) %>%
    dplyr::filter(!id %in% keep_nonc) %>%
    pull(id)
  remove_observations(df, df$id %in% remove_nonc)
}

#' @export
remove_c_duplicates <- function(df, col_names) {
  stopifnot(all(col_names %in% names(df)) | "id" %in% names(df))
  if (!all(df$class %in% c("C")))
    return(list(clean = df, dirty = data.frame()))
  stopifnot(length(unique(df$id)) == nrow(df))
  keep_c <-
    df %>%
    dplyr::arrange(!!!syms(col_names), dplyr::desc(id)) %>%
    dplyr::distinct(!!!syms(col_names),
                    .keep_all = T) %>%
    pull(id)
  remove_c <-
    df %>%
    dplyr::filter(!id %in% keep_c) %>%
    pull(id)
  out <- remove_observations(df, df$id %in% remove_c)
  stopifnot(no_duplicates(out$clean, col_names))
  return(out)
}

#' @export
remove_ms_duplicates <- function(df) {
  keep_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::arrange(dplyr::desc(id)) %>%
    dplyr::distinct(question_id, country_id, coder_id, historical_date, code,
                    .keep_all = T) %$% id
  remove_ms <-
    df %>%
    dplyr::filter(question_type == "S") %>%
    dplyr::filter(!id %in% keep_ms) %$% id
  remove_observations(df, df$id %in% remove_ms)
}

#' @export
print_by_name <- function(df) {
  df %>%
    dplyr::group_by(name, class) %>%
    dplyr::summarize(n = n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country <- function(df) {
  df %>%
    dplyr::group_by(country_name) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(dplyr::desc(n)) %>%
    as.data.frame(stringsAsFactors = F) %>%
    print
}

#' @export
print_by_country_year <- function(df) {
  df %>%
    dplyr::group_by(country_name, year) %>%
    dplyr::summarize(n = dplyr::n()) %>%
    dplyr::arrange(country_name, year) %>%
    as.data.frame(stringsAsFactors = F) %T>%
    print
}

#' Traverse coder-country network
#'
#' For a specific C variable and from a given start country,
#' \code{traverse} returns a DataFrame of countries accessible through
#' bridge/lateral coding.
#'
#' @param x \code{DataFrame} long-formatted coder-level data
#' @param root Country_id start position
#'
#' @details Ideally, for a particular C variable, every country (node)
#'     should be linked through bridge/lateral coding. Countries which
#'     do not appear in the output \code{DataFrame} are isolated
#'     nodes.
#'
#' @export
traverse <- function(x, root = 20) {
  aux <- data.frame(country_id = NULL, count = NULL)

  # For each country node, loop over each coder and for
  # every child country node if we haven't marked it yet with our
  # ad-hoc `aux` "stack", recursively descend.
  recurse <- function(parent = root) {
    coders <- x$coder_id[x$country_id == parent]

    for (c_coder in coders) {
      countries <- x$country_id[x$coder_id == c_coder & x$country_id != parent]

      if (length(countries) > 0) {
        for (c_country in countries) {
          if (c_country != root & !c_country %in% aux$country_id) {
            aux <<- rbind(aux, data.frame(country_id = c_country, count = 1))

            recurse(c_country)
          } else {
            aux$count[aux$country_id == c_country] <<-
              aux$count[aux$country_id == c_country] + 1
          }
        }
      }

    }
  }

  recurse
  return(aux)
}

#' Country-date
#'
#' Checks whether a given string is properly formatted as a
#' country-date string.
#'
#' @param x Character vector
#'
#' @details A country-date string consists of a 1-3 lettered V-Dem
#'     country identifier, \code{country_text_id}, concatenated with a
#'     space to a year-month-day date, \code{historical_date}. The
#'     resulting string is mostly used as the rownames of matrices in
#'     order to identify each country-date observation.
#'
#'     Ideally, we would create a \code{country_date} S3 class so that
#'     we can avoid the performance cost of constantly checking
#'     whether our country-date strings are properly
#'     formatted. Unfortunately, while R allows character vectors with
#'     additional attributes to be set as the rownames of matrices,
#'     when subsetting a matrix the resulting rownames loses all of
#'     those attributes. We can partially avoid the performance
#'     problem in a less elegant with memoisation.
#'
#' @section Warning: No attempt is currently made to ensure that the
#'     date portion of a country-date string is a valid date beyond
#'     checking the number of digits.
#'
#'     \code{is_country_date} will also always return \code{FALSE} for
#'     missing values; however, \code{NULL} will return
#'     \code{logical(0)}.
#'
#' @return Logical vector.
#'
#' @examples
#' is_country_date(c("AFG 1900-01-01", "pilot_1_v1", "BFD 2001"))
#'
#' @family country-date functions
#' @export
is_country_date <- function(x, party = FALSE) {
  if (party) {
    grepl("^[A-Z]{3} \\d{6} \\d{4}-\\d{2}-\\d{2}$", x, perl = T)
  } else {
    grepl("^[A-Z]{3} \\d{4}-\\d{2}-\\d{2}$", x, perl = T)
  }
}

assert_str <- function(x, party = FALSE) {
  if (any(!is_country_date(x, party)))
    stop("Invalid country-date string", call. = F)
}


#' Vignette ratings
#'
#' Indicates whether a country-date represents a vignette.
#'
#' @param x Character vector of country-dates
#' @param na.rm Whether to set \code{NA} values to false.
#'
#' @details Vignettes are identified by unique constructed from the
#'     vignette type, threshold, and version.  Note, we merge
#'     historical vignettes into contemporary when the question text
#'     hasn't changed --- which so far includes contemporary pilot
#'     vignettes only --- meaning that the raw data contained in a
#'     vignette row in a V-Dem country-date data matrix may not match
#'     directly to the raw data in our database.
#'
#' @return Logical vector
#'
#' @examples
#' is_vignette(c("AFG 1900-01-01", "historical_1_v2", "pilot_1_v1"))
#'
#' @family country-date functions
#'
#' @export
is_vignette <- function(x, na.rm = T) {
  b <- grepl("^(A|B)_", x)

  if (!isTRUE(na.rm))
    b[is.na(x)] <- NA

  b
}

#' Extract party_id from the string
#'
#' @param x Character vector
#'
#' @details It works only for the strings that are used in the party survey
#'
#' @return Integer vector of length 1 to 6 separated by space.
#'
#' @examples
#' get_cpid("RUS 2244 2016-09-18")
#' @family country_date functions
#'
#' @export
get_party_id <- function(x) {
  assert_str(x, party = TRUE)
  as.numeric(gsub("^\\S{3} | \\d{4}-\\d{2}-\\d{2}$", "", x))
}

#' Extract date or country from country-date
#'
#' Extracts the individual components from a country-date string
#'
#' @param x Character Vector
#'
#' @details Country-date strings are a string concatenation of a three
#'     letter country ID, \code{country_text_id}, and an ISO 8601
#'     date, \code{historical_date}. \code{get_date} is a vectorised
#'     function that returns the date part, converted using
#'     \code{as.Date}.
#'
#' @return Date vector
#'
#' @examples
#' get_date("SWE 1988-04-20")
#'
#' @family country_date functions
#'
#' @export
get_date <- function(x, party = FALSE) {
  assert_str(x, party)
  if (party) {
    sub("^\\S{3} \\d{6} ", "", x, perl = T) %>% as.Date
  } else {
    sub("^\\S{3} ", "", x, perl = T) %>% as.Date
  }
}

#' @details The \code{get_text_id} function is the vectorised
#'     counterpart to \code{get_date} that returns the
#'     \code{country_text_id} components
#'
#' @examples
#' get_text_id("DEU 1951-02-23")
#'
#' @rdname get_date
#' @export
get_text_id <- function(x, party = FALSE)  {
  assert_str(x, party)
  sub("\\s\\d.*$", "",  x, perl = T) %>% unclass
}

#' Sort a vector of country-dates
#'
#' Sorts a character vector of country-dates based on the
#' \code{country_text_id} prefixes.
#'
#' @param x Character Vector
#' @param decreasing Logical indicating whether to sort by decreasing
#'     order.
#' @param na.last Logical indicating whether NAs should be appending
#'     to the end or beginning of the sorted vector.
#'
#' @details Sorts first country-date strings followed by vignette
#'     identifiers. The fact that we append vignettes to the end is
#'     simply a convenience for when working with the MM code.
#'
#' @examples
#' v <- c("USA 1920-01-01", "MEX 1902-01-01", "MEX 1900-01-01",
#'        "pilot_1_v1", "pilot_2_v1")
#' sort_text_id(v)
#'
#' @family country-date functions
#'
#' @export
sort_text_id <- function(x, decreasing = F, na.last = T, party = FALSE){
  b <- grepl("^\\S{3}\\s", x)

  # Assert first that we have valid strings and vignette tags. This
  # sort function is the only `country-date` specific function that
  # should be able to deal with vignette identifiers.
  assert_str(x[b], party)
  if (any(!is_vignette(x[!b])))
    stop("Invalid vignette string", call. = F)

  out <- c(sort(x[b], decreasing = decreasing), sort(x[!b], decreasing = decreasing))
  if (isTRUE(na.last))
    c(out, x[is.na(x)])
  else
    c(x[is.na(x)], out)
}

#' Date to year
#'
#' Return the four digit year from a Date object.
#'
#' @param date Date or character
#'
#' @return Integer
#'
#' @examples
#' v <- as.Date(c("1900-01-01", "1901-01-01"))
#' to_year(v)
#'
#' @export
to_year <- function(date) UseMethod("to_year")

#' @export
to_year.Date <- function(date) {
  x <- rep(NA_real_, length(date))

  b <- !is.na(date)
  x[b] <- format(date[b], "%Y") %>% as.integer

  x
}

#' @export
to_year.character <- function(date) {
  x <- rep(NA_real_, length(date))

  b <- !is.na(date)
  x[b] <- substr(date, 1, 4) %>% as.integer

  x
}

#' Year to date
#'
#' @export
year_to_date <- function(v) {
  as.Date(paste0(v, "-12-31"), format = "%Y-%m-%d")
}

#' Date to year
#'
#' @export
date_to_year <- function(date) UseMethod("to_year")
#' @export
find_vars <- function(vari, qtable) {

  if (!vari %in% qtable$name)
    stop("The variable is not in the question table")

  if (vari == "e_regionpol_6C")
    return("e_regionpol_6C")

  if (vari == "e_uds_median")
    return(c("e_uds_median", "e_uds_mean", "e_uds_pct025", "e_uds_pct975"))

  if (grepl("_\\dC$", vari)) {
    plainvar <- gsub("_\\dC", "", vari)
    return(paste0(plainvar, c("_3C", "_4C", "_5C")))
  }

  df <- qtable[qtable$name == vari, ]

  if (df$to_dichotomize) return(NULL)

  if (is.na(df$additional_versions))
    return(vari)


  # mm
  mm_vars <- c("_codelow", "_codehigh", "_sd",
               "_osp", "_osp_codelow", "_osp_codehigh", "_osp_sd",
               "_ord", "_ord_codelow", "_ord_codehigh",
               "_mean",
               "_nr")

  #other_index
  other_index <- c("_codelow", "_codehigh")

  # index (code_low code_high)
  index_vars <- c("_codelow", "_codehigh", "_sd")

  #percent_vars
  percent_vars <- c("_codelow", "_codehigh", "_sd", "_mean", "_nr")

  # accountability exception
  account_vars <- c("_codelow", "_codehigh", "_osp", "_osp_codelow", "_osp_codehigh")

  # MS no mm
  ms_vars <- c("_nr")

  if (df$additional_versions == "*_nr") {
    varis <- ms_vars
  } else if(df$additional_versions == "*_codelow, *_codehigh, *_sd") {
    varis <- index_vars
  } else if(df$additional_versions == "*_osp, *_ord, *_codelow, *_codehigh, *_sd, *_mean, *_nr") {
    varis <- mm_vars
  } else if(df$additional_versions == "*_osp, *_codelow, *_codehigh") {
    varis <- account_vars
  } else if(df$additional_versions == "*_codelow, *_codehigh") {
    varis <- other_index
  } else if(df$additional_versions == "*_codelow, *_codehigh, *_sd, *_mean, *_nr") {
    varis <- percent_vars
  } else if (grepl("^e", vari) && !is.na(df$additional_versions)) {
    varis <- gsub("*", "", unlist(strsplit(df[, "additional_versions"], ", ")), fixed = TRUE)
  }

  if (!exists("varis")) {
    out <- vari
  } else {
    out <- c(vari, paste0(vari, varis))
  }

  if (grepl("_\\d+$", vari)) {
    out <- gsub(vari %^% "_nr", gsub("_\\d+$", "", vari) %^% "_nr", out)
  }
  out

}

#' @describeIn trans_helpers Translate question tag names to question labels
#' @export
to_qlabels <- function(v, ttable) {
  # We call this function with the columns of a data.frame, so strip
  # out all the generated codelow/high, sd, mean etc etc.
  basetags <- get_root(v)

  # Unlike to_qids and to_qnames, some of our tag names may not be
  # in our lookup table. Instead of erroring, just return an empty
  # string unless it's historical in which case try the v2 form.
  #basetags <- ifelse(is.hist(basetags) & !basetags %in% ttable$name,
  #                  "v2" %^% substring(basetags, 3),
  #                  basetags)

  out <- character(length(v))
  out[basetags %in% ttable$name] <-
    trans(basetags[basetags %in% ttable$name],
          to = "label", ttable = ttable, by = "name")

  out[is.na(out)] <- ""
  if (any(out == ""))
    info("Missing labels for: " %^% v[out == ""])
  return(out)
}

#' Variable labels
#'
#' Sets either Stata or SPSS variable labels for a data frame by
#' adjusting the attributes of the object.
#'
#' @param x \code{DataFrame}
#' @param labels CharacterVector of labels for each column.
#'
#' @name label
NULL

#' @describeIn label Set SPSS variable labels
#' @export
set_spss_labels <- function(x, labels) {
  if (!inherits(x, "data.frame"))
    stop("SPSS labels can only be set on data frames", call. = F)

  if (length(labels) != ncol(x))
    stop("Length mismatch between labels and columns", call. = F)

  for (i in seq_along(x))
    attr(x[, i], "label") <- labels[i]

  x
}

#' @describeIn label Set Stata variable labels
#' @export
set_stata_labels <- function(x, labels) {
  if (!inherits(x, "data.frame"))
    stop("Stata labels can only be set on data frames", call. = F)

  if (length(labels) != ncol(x))
    stop("Length mismatch between labels and columns", call. = F)

  attr(x, "var.labels") <- labels
  x
}

#' Ordinalize numeric vector
#'
#' Ordinalize an interval scaled numeric vector based on
#' automatic equal-spaced intervals.
#'
#' @param v NumericVector
#' @param categories Desired number of ordinal categories
#' @param max Maximum of \code{v} scale
#' @param min Minimum of \code{v} scale
#' @param vec Bins passed to \code{\link{findInterval}}
#' @param ... Additional arguments passed to \code{ordinalize}
#'
#' @details \code{ordinalize} should not be confused with the
#'     \code{\link{ord}} function. The latter ordinalizes the MM
#'     output using an ordinal scale transformation to map back to the
#'     original ordinal answer categories. The former simply splits up
#'     a numeric vector into equal intervals and assigns the given
#'     number of categories.
#'
#'     Note, ordinalization is is done using left-open intervals. For
#'     example, the lowest category from the default \code{ord_5C}
#'     output is 0 corresponding to \code{N <= .2}, the second is 1
#'     for values \code{.2 < N <= .5}, and etc etc.
#'
#' @section \code{ord_3C}:
#'     The \code{ord_3C} by default operates slightly different from the
#'     other convenience functions. Rather than being a balanced
#'     ordinalization (\emph{i.e.,} equally spaced bins determining
#'     membership in each category), \code{ord_3C} passes in a \code{vec}
#'     of \code{c(0, .25, .5, 1)}. The rationale is that 3 category
#'     versions of indices are meant to represent "Autocratic" (0 -
#'     .25), "Electoral Authoritarian" (.25 - .5), and "Minimally
#'     Democratic" (.5 - 1).
#'
#'
#' @examples
#' (v <- runif(5))
#'
#' ordinalize(v, categories = 5)
#' ord_5C(v)
#'
#' ord_4C(v)
#' ordinalize(v, categories = 4)
#'
#' # Note the difference b/w output
#' ordinalize(v, categories = 3)
#' ord_3C(v)
#'
#' @export
ordinalize <- function(v, categories, max = 1, min = 0,
                       vec = seq(min, max, by = max / categories)) {
  if (min(v, na.rm = T) < min | max(v, na.rm = T) > max)
    stop("Out of bounds vector elements", call. = F)

  x <- findInterval(v, vec = vec, left.open = T, all.inside = T)

  (x - 1) / (categories - 1)
}

#' @describeIn ordinalize Ordinalize to 3 categories according to
#'     V-Dem rules. See the section, Details.
#' @export
ord_3C <- function(...) {
  Call <- match.call(expand.dots = T)

  if (is.null(Call[["vec"]])) {
    scale_max <- Call[["max"]] %||% 1
    scale_min <- Call[["min"]] %||% 0

    vec <- c(scale_min,
             .25 * (scale_max - scale_min),
             2 * (.25 * (scale_max - scale_min)),
             scale_max)

    ordinalize(categories = 3, vec = vec, ...)
  } else
    ordinalize(categories = 3, ...)
}

#' @describeIn ordinalize Ordinalize to 4 categories
#' @export
ord_4C <- function(...) ordinalize(categories = 4, ...)

#' @describeIn ordinalize Ordinalize to 5 categories
#' @export
ord_5C <- function(...) ordinalize(categories = 5, ...)


#' @export
sort_multiple_selection <- function(v) {
  original_v <- v
  short_vars <- gsub("_\\d+$", "", v) %>% gsub("_nr$", "", .)
  vars <- grep_("_\\d+$", v) %>% gsub("_\\d+$", "", .) %>% unique

  lapply(vars, function(vv) {
    # vv <- c_vars[1]
    positions <- which(short_vars == vv)
    varvar <- v[positions]
    nums <- gsub("^.*_(\\d+)$", "\\1", varvar)
    nums[grepl("_nr$", nums)] <- NA_character_
    nums <- as.numeric(na.omit(nums)) %>% sort
    outvars <- vv %^% "_" %^% as.character(nums)
    if (vv %^% "_nr" %in% v) {
      outvars <- c(outvars, vv %^% "_nr")
    }
    v[positions] <<- outvars
    return(NULL)
  }) %>% invisible

  stopifnot(
    all(v %in% original_v),
    all(original_v %in% v),
    length(unique(v)) == length(unique(original_v)))
  return(v)
}

#' Lock task in make table
#'
#' @export
lock_task <- function(id = Sys.getenv("TASK_ID"), db) {
  DBI::dbGetQuery(db,
                  "UPDATE pipe.make SET lock = TRUE WHERE task_id = " %^% id %^% ";")
}

#' Update task status of make table
#'
#' @export
update_task_status <- function(status = "done",
                               id = Sys.getenv("TASK_ID"),
                               db) {
  if (id == "")
    stop("No TASK_ID specified!")

  DBI::dbGetQuery(db,
                  "UPDATE pipe.make " %^%
                    "SET status = '" %^% status %^% "', " %^%
                    "ts = NOW() " %^%
                    "WHERE task_id = " %^% id %^% ";")
}

#' @export
update_task_status_no_timestamp <- function(status = "done",
                                            id = Sys.getenv("TASK_ID"),
                                            db) {
  if (id == "")
    stop("No TASK_ID specified!")

  DBI::dbGetQuery(db,
                  "UPDATE pipe.make " %^%
                    "SET status = '" %^% status %^% "' " %^%
                    "WHERE task_id = " %^% id %^% ";")
}

#'@export
pg_update_timestamp <- function(id, db) {
  vbase::pg_send_query(db, "UPDATE pipe.make SET ts = NOW() WHERE task_id = " %^% id %^% ";")
}

#' @export
pg_update_many_timestamps <- function(task_ids, db) {
  for (task_id in task_ids) {
    vbase::pg_update_timestamp(task_id, db)
    Sys.sleep(1)
  }
}

#'@export
pg_update_var <- function(df, name, db) {
  qids <- unique(df$question_id)
  stopifnot(length(qids) == 1)
  vbase::pg_send_query(db,
                       "DELETE FROM " %^% name %^% " " %^%
                         "WHERE question_id = " %^% qids %^% ";")
  vbase::pg_append_table(df, name, db)
}

#' Row/Column-wise Median and Standard Deviation
#'
#' Calculate the median and standard deviation by column or row given
#' a numeric matrix. \code{NA}s will not be removed.
#'
#' @param x A numeric matrix
#'
#' @return A numeric vector
#'
#' @examples
#' m <- matrix(1:9, 3, 3)
#' m[1, 1] <- NA
#'
#' colMedians(m)
#' rowSDs(m)
#'
#' @export
colMedians <- function(x) UseMethod("colMedians")

#' @rdname colMedians
#' @export
colSDs <- function(x) UseMethod("colSDs")

#' @rdname colMedians
#' @export
rowMedians <- function(x) UseMethod("rowMedians")

#' @rdname colMedians
#' @export
rowSDs <- function(x) UseMethod("rowSDs")

#' @export
hpd <- function(m, prob) {
  out <- coda::HPDinterval(coda::as.mcmc(m), prob = prob)

  suffix <- sub("^.*[.]", "", prob)
  colnames(out) <- c("codelow", "codehigh") %^% suffix

  out
}

#' Summarise posterior distributions
#'
#' \code{dist_summary} summarises a country-date matrix where each column
#' is a posterior distribution.
#'
#' @param m Matrix, either a coerced parameter from a \code{stanfit} object
#'     or output from the \code{osp} or \code{ord} transformation
#'     functions. Columns correspond to country-dates.
#' @param expanded.names Row names to expand the summarised time
#'     series to using \code{\link{stretch}}.
#' @param drop.vignettes Boolean. Whether to drop vignette rows prior
#'     to summarisation. Note, if set to \code{FALSE}, but
#'     \code{expanded.names} is not \code{NULL}, the function will
#'     return an error since vignette identifiers are not valid
#'     country-dates.
#' @param ... Additional arguments passed to the \code{\link{stretch}}
#'     function.
#'
#' @details \code{dist_summary} will preserve entire columns of
#'     \code{NA} under the assumption that they're missing
#'     country-dates; however, it will fail when only a single value
#'     within a column is \code{NA} since we never want partial
#'     missingness within our posterior distribution.
#'
#'     More importantly, why did we call this function
#'     \code{dist_summary} when there's clearly a much better option?
#'     Great question, besides to add to the general confusion
#'     surrounding this package, it's also nice to minimize conflicts
#'     with \code{dplyr}.
#'
#' @return DataFrame containing the mean, median, sd,
#'     codehigh/low68, codehigh/low95.
#'
#' @export
dist_summary <- function(m, expanded.names = NULL, drop.vignettes = T,
                         utable = NULL, ...)  UseMethod("dist_summary")

#' @export
dist_summary.matrix <- function(m, expanded.names = NULL, drop.vignettes = T,
                                utable = NULL, party = FALSE, ...) {
  if (isTRUE(drop.vignettes) & !is.null(colnames(m)))
    m <- m[, !is_vignette(colnames(m))]

  # Split missing and nonmissing columns since `hpd` will choke on NA
  missing_b <- colSums(is.na(m)) == nrow(m)
  nonmissing <- m[, !missing_b, drop = F]

  m_mean <- colMeans(nonmissing)
  m_median <- colMedians(nonmissing)
  m_sd <- colSDs(nonmissing)

  hpd95 <- hpd(nonmissing, .95)
  hpd68 <- hpd(nonmissing, .68)

  nonmissing_summary <- cbind(m_mean, m_median, m_sd, hpd68, hpd95)

  summarised_vars <- c("mean", "median", "sd", "codelow68", "codehigh68",
                       "codelow95", "codehigh95")

  # TODO: If there's no missing, we should avoid copying
  out <- matrix(NA, ncol(m), 7, dimnames = list(colnames(m), summarised_vars))
  out[!missing_b, ] <- nonmissing_summary

  if (!is.null(colnames(m))) {
    df <- if (!is.null(expanded.names))
      stretch(out, expanded.names, utable = utable, party = party, ...) %>% as.data.frame
    else
      as.data.frame(out)
    if (party) {
      df$country_text_id <- row.names(df) %>% sub(" \\d{4}-\\d{2}-\\d{2}$", "", x = .)
    } else {
      df$country_text_id <- row.names(df) %>% get_text_id(party)
    }

    df$historical_date <- row.names(df) %>% get_date(party)
    row.names(df) <- NULL

    return(df)
  } else if (!is.null(expanded.names))
    stop("Missing country-dates from original matrix", call. = F)

  as.data.frame(out)
}

#' @export
b_summary <- function(m) {

  m_mean <- colMeans(m)
  m_median <- colMedians(m)
  m_sd <- colSDs(m)
  hpd95 <- hpd(m, .95)
  hpd68 <- hpd(m, .68)

  out <- cbind(m_mean, m_median, m_sd, hpd68, hpd95, colnames(m))
  colnames(out) <- c("mean", "median", "sd", "codelow68", "codehigh68",
                     "codelow95", "codehigh95", "coder_id")
  rownames(out) <- NULL
  out
}

#' @export
fix_stat_columns <- function(df, varname) {
  df %<>% dplyr::select(-mean)
  colnames(df) <- dplyr::case_when(
    colnames(df) == "country_text_id" ~ "country_text_id",
    colnames(df) == "party_id" ~ "party_id",
    colnames(df) == "historical_date" ~ "historical_date",
    colnames(df) == "year" ~ "year",
    colnames(df) == "median" ~ varname,
    T ~ varname %^% "_" %^% colnames(df))
  df
}

#' @export
hli_summary <- function(full.ma, VARNAME) {
  info("Summarising posteriors for " %^% VARNAME)
  cd <- dist_summary(t(full.ma))
  cy <- cy.day_mean(cd, historical_date, country_text_id)
  cd <- fix_stat_columns(cd, VARNAME)
  cy <- fix_stat_columns(cy, VARNAME)
  return(list(cd = cd, cy = cy, thin_post = full.ma))
}
#' Pick external source
#'
#' Guesses the name of external source basing on the file name
#'
#' @param file_name Full or relative path to the file
#'
#' @details For now, it's the best way to identify the name of the source
#' although it is not recommended to use it in different context. This function is
#' vectorised, hence it can be used not only as a part of other functions but on its own.
#'
#' @return Character vector depending on the length of the input.
#'
#' @examples
#' \dontrun{guess_source_by_file_name(list.files("~/Documents/edata/2021/upd", full.names = TRUE))}
#'
#' @export
guess_source_by_file_name <- function(file_name = "area") {
  file_name <- basename(file_name)
  source <- dplyr::case_when(
    # download Haber & Menaldo data twice
    # for one of them assign a slightly different name
    grepl("Haber", file_name) ~ "habmen",
    grepl("area", file_name) ~ "area",
    grepl("ddrevisited", file_name) ~ "cheibub",
    grepl("sp_dyn|life_expectancy|infant_mortality_rate|maternal_mortality", file_name) ~ "gapminder",
    grepl("EducationalIn", file_name) ~ "peedgini",
    grepl("powell_thyne", file_name) ~ "pt_coup",
    grepl("lied_v\\d+", file_name) ~ "lexical_index",
    grepl("_Data[.][csv|xlsx]", file_name) ~ "wbgi",
    grepl("Country_and_Territory_Ratings", file_name) ~ "fh",
    grepl("p5v2018", file_name) ~ "polity",
    grepl("PIPE", file_name) ~ "przeworski",
    grepl("_Compact", file_name) ~ "clio",
    grepl("uds_summary", file_name) ~ "uds",
    grepl("FinalCHAT", file_name) ~ "radio",
    grepl("National_COW", file_name) ~ "cowec",
    grepl("democracy-v\\d", file_name) ~ "boix",
    grepl("estimates_all_long_\\d{6}.rds$", file_name) ~ "gdppop",
    grepl("CPI\\d{4}", file_name) ~ "ti_cpi",
    grepl("qog", file_name) ~ "bnr",
    file_name == "wb_pop" ~ "wb_pop",
    TRUE ~ NA_character_
  )
  return(source)
}

choose_mtable <- function(data_key) {
  func_name <- switch(data_key,
                      "area" = "cow",
                      "boix" = "cow",
                      "cheibub" = "cow",
                      "cowec" = "cow",
                      "gapminder" = "cow",
                      "habmen" = "cow",
                      "lexical_index" = "cow",
                      "polity" = "cow",
                      "pt_coup" = "cow",
                      "uds" = "cow",
                      "bnr" = "iso",
                      "clio" = "iso",
                      "peedgini" = "iso",
                      "ti_cpi" = "iso",
                      "wbgi" = "iso",
                      "wb_pop" = "iso",
                      "gdppop" = "gw",
                      "radio" = "all_df",
                      "fh" = "all_df",
                      "przeworski" = "mtable_list")
  return(func_name)
}

area <- function(file_name, mtable) {
  stopifnot(c("cshapes", "sf") %in% rownames(installed.packages(lib.loc = .libPaths()[1])))
  stopifnot(packageVersion("cshapes") == "2.0")

  df <- cshapes::cshp(useGW = FALSE, dependencies = TRUE)
  df <- dplyr::mutate(df, area = sf::st_area(df))

  df <- sf::st_drop_geometry(df) %>%
    dplyr::select(cowcode, country_name, start, end, status, owner, area) %>%
    dplyr::mutate(start_year = to_year(start), end_year = to_year(end)) %>%
    dplyr::arrange(cowcode, start)

  df_long <- lapply(seq_along(rownames(df)), function(row) {

    year <- with(df, start_year[row] : end_year[row])

    repl <- function(x, y) {rep(x, length(y))}

    out_df <- data.frame(
      ccode = with(df, repl(cowcode[row], year)),
      country_name = with(df, repl(country_name[row], year)),
      year = year,
      start_date = with(df, repl(start[row], year)),
      end_date = with(df, repl(end[row], year)),
      area = with(df, repl(area[row], year)),
      stringsAsFactors = FALSE
    )
    return(out_df)
  }) %>%
    dplyr::bind_rows() %>%
    dplyr::group_by(ccode, year) %>%
    dplyr::arrange(end_date) %>%
    dplyr::filter(dplyr::row_number() == dplyr::n()) %>%
    dplyr::mutate(e_area = as.numeric(area)) %>%
    dplyr::ungroup()

  df_rec <- dplyr::mutate(df_long, ccode = dplyr::case_when(
    ccode == 255 & year == 1990 ~ 260,
    ccode == 901 ~ 900,
    ccode == 911 & year < 1949 ~ 910,
    ccode == 912 & year < 1949 ~ 910,
    ccode == 5518 & year < 1911 ~ 551,
    ccode == 822 & year < 1946 ~ 820,
    ccode == 821 & year < 1946 ~ 820,
    ccode == 7020 ~ 704,
    ccode == 521 & year < 1960 ~ 139,
    ccode == 5200 & year < 1960 ~ 139,
    ccode == 827 & year < 1946 ~ 830,
    ccode == 21 & dplyr::between(year, 1907, 1919) ~ 20,
    ccode == 732 & dplyr::between(year, 1945, 1947) ~ 730,
    ccode == 7506 & year > 1947 ~ 750,
    ccode == 681 & year < 1962~ 680,
    ccode == 6801 & year < 1967 ~ 680,
    ccode == 678 & year == 1990 ~ 679,
    ccode == 460 & year < 1922 ~ 461,
    ccode == 815 & year < 1954 ~ 817,
    ccode == 7351 & dplyr::between(year, 1905, 1919) ~ 740,
    TRUE ~ as.numeric(ccode)
  )) %>%
    dplyr::group_by(ccode, year) %>%
    dplyr::summarize(e_area = sum(e_area, na.rm = TRUE)) %>%
    dplyr::ungroup()

  ru_df <- lapply(c(516, 517), function(cid) {
    dplyr::filter(df_long, ccode == 515, year < 1962) %>%
      dplyr::mutate(ccode = cid, e_area = as.numeric(e_area)) %>%
      dplyr::select(ccode, year, e_area)
  }) %>% dplyr::bind_rows()

  df_rec %<>% dplyr::bind_rows(ru_df)

  palestine_df <- dplyr::filter(df_rec, ccode %in% c(665, 6511)) %>%
    dplyr::mutate(country_id = dplyr::case_when(
      ccode == 665 ~ 209,
      ccode == 6511 ~ 138,
      TRUE ~ as.numeric(ccode)
    )) %>% dplyr::select(country_id, year, dplyr::everything(), -ccode)

  area_df <- dplyr::inner_join(df_rec, mtable[, c("country_id", "ccode", "year")], by = c("ccode", "year")) %>%
    dplyr::bind_rows(palestine_df) %>%
    dplyr::mutate(e_area = round(e_area / 1000000, 3)) %>%
    dplyr::select(-ccode)

  return(area_df)
}

cheibub <- function(file_name, mtable) {
  cheibub <- read_file(file_name) %>%
    dplyr::select(ccode = cowcode, ctryname, year, e_chga_demo = democracy)
  cheib_df <- cheibub %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 255 & year == 1990 ~ 260,
      ctryname == "Serbia" & is.na(ccode) ~ 345,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, everything(), -ctryname, -ccode)
  return(cheib_df)
}

gapminder <- function(file_name, mtable, country_unit) {
  gapmind <- read_file(file_name, header = TRUE)

  vname <- dplyr::case_when(
    grepl("maternal_mortality", basename(file_name)) ~ "e_pematmor",
    grepl("sp_dyn_tfrt", basename(file_name)) ~ "e_miferrat",
    grepl("life_expectancy", basename(file_name)) ~ "e_pelifeex",
    grepl("infant_mortality_rate", basename(file_name)) ~ "e_peinfmor",
    TRUE ~ NA_character_
  )
  stopifnot(!is.na(vname))

  gapmind_df <- dplyr::mutate_if(gapmind, is.logical, as.numeric) %>%
    dplyr::mutate_if(is.integer, as.numeric) %>%
    reshape2::melt(id.vars = "country", variable.name = "year", value.name = vname) %>%
    dplyr::mutate(year = as.numeric(as.character(year)))

  to_delete <- is.na(gapmind_df[, vname])
  gapm_nona <- gapmind_df[!to_delete,]

  add <- dplyr::mutate(gapm_nona, country_id = dplyr::case_when(
    grepl("Palestine", country) ~ 128,
  )) %>%
    dplyr::filter(!is.na(country_id)) %>%
    dplyr::semi_join(country_unit, by = c("country_id", "year"))

  gapm_df <- gapm_nona %>%
    dplyr::mutate(country = dplyr::case_when(
      grepl("Kyrgyz", country) ~ "Kyrgyzstan",
      grepl("Congo, D", country) ~ "Democratic Republic of the Congo",
      grepl("Congo, R", country) ~ "Congo",
      grepl("d'Ivoire", country) ~ "Ivory Coast",
      grepl("Lao$", country) ~ "Laos",
      grepl("Macedonia", country) ~ "Macedonia",
      grepl("Serbia", country) ~ "Yugoslavia",
      grepl("Slovak", country) ~ "Slovakia",
      grepl("Timor-Leste", country) ~ "East Timor",
      grepl("^United States$", country) ~ "United States of America",
      country == "Yemen" & dplyr::between(year, 1962, 1989) ~ "Yemen Arab Republic",
      country == "South Korea" & dplyr::between(year, 1788, 1948) ~ "Korea",
      TRUE ~ country
    )) %>%
    dplyr::inner_join(.,mtable[, c("country_name", "year", "country_id")],
                      by = c(c("country" = "country_name"), "year")) %>%
    dplyr::bind_rows(add) %>%
    dplyr::select(country_id, year, dplyr::everything(), -country) %>%
    dplyr::arrange(country_id, year)
  return(gapm_df)
}

peedgini <- function(file_name, mtable) {
  clio_df <- read_file(file_name, sheet = 2) %>%
    setNames(c("numeric_code", "country_name", "year", "e_peedgini")) %>%
    dplyr::arrange(numeric_code, year) %>%
    dplyr::inner_join(mtable[, c("country_id", "year", "numeric_code")], by = c("numeric_code", "year")) %>%
    dplyr::select(country_id, dplyr::everything(), -numeric_code, -country_name)
}

pt_coup <- function(file_name, mtable) {
  pothy_df <-	suppressWarnings(read.table(file_name, sep = "\t", header = TRUE,
                                          stringsAsFactors = FALSE)) %>%
    dplyr::select(ccode, year, dplyr::starts_with("coup")) %>%
    reshape2::melt(id.vars = c("ccode", "year"), variable.name = "coup_event", value.name = "e_pt_coup") %>%
    dplyr::group_by(ccode, year) %>%
    dplyr::arrange(e_pt_coup) %>%
    dplyr::filter(dplyr::row_number() == dplyr::n()) %>%
    dplyr::ungroup() %>%
    dplyr::arrange(ccode, year) %>%
    dplyr::select(-coup_event) %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 678 & year == 1990 ~ 679,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "country_id", "year")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything()) %>%
    dplyr::distinct() %>%
    dplyr::select(-ccode)
  return(pothy_df)
}

lexical_index <- function(file_name, mtable) {
  lexind_df <- read_file(file_name) %>%
    dplyr::select(countryn, cow, year, lexical_index) %>%
    setNames(c("country_name", "ccode", "year", "e_lexical_index")) %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 89 ~ 90,
      ccode == 300 ~ 305,
      ccode == 816 & year < 1900 ~ 817,
      ccode == 255 & year == 1990 ~ 260,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")],
                      by = c("ccode", "year")) %>%
    dplyr::select(-country_name, -ccode) %>%
    dplyr::select(country_id, dplyr::everything()) %>%
    dplyr::distinct()
  return(lexind_df)
}

wbgi <- function(file_name, mtable) {
  vars <- c("e_wbgi_cce", "e_wbgi_gee", "e_wbgi_pve", "e_wbgi_rle", "e_wbgi_rqe", "e_wbgi_vae")

  wbgi <- read_file(file_name, header = TRUE) %>%
    dplyr::filter(`Series Code` %in% c("CC.EST", "GE.EST", "PV.EST", "RL.EST", "RQ.EST", "VA.EST")) %>%
    dplyr::select(-`Series Name`)
  names(wbgi) <- trimws(names(wbgi), "both")

  wbgi <- reshape2::melt(wbgi, id.vars = c("Country Name", "Country Code", "Series Code")) %>%
    setNames(c("country_name", "iso3", "indicator", "year", "val")) %>%
    reshape2::dcast(country_name + iso3 + year ~ indicator, value.var = "val") %>%
    dplyr::mutate(year = gsub(" (\\[YR\\d+\\])", "", year),
                  year = as.numeric(as.character(year)))
  names(wbgi)[4:9] <- vars
  to_delete <- is.na(wbgi[, 4:9]) %>% apply(1, all)
  wbgi_df <- wbgi[!to_delete,] %>%
    dplyr::inner_join(mtable[, c("country_id", "iso3", "year")],
                      by = c("iso3", "year")) %>%
    dplyr::select(country_id, dplyr::everything(), -country_name, -iso3) %>%
    dplyr::mutate_if(is.character, as.numeric)

  return(wbgi_df)
}

fh <- function(file_name, mtable, country_unit) {
  fh_df <- lapply(2:3, function(sh_n) {
    dirty_xls <- read_file(file_name, sheet = sh_n)

    nums <- dirty_xls[1, ] %>%
      t() %>%
      .[, 1] %>%
      .[grepl("\\d", .)] %>%
      lapply(function(x) rep(x, 3)) %>%
      unlist %>% gsub("Aug|Nov|Dec|Jan|[.]| |\\d{4}-", "", x = .) %>%
      gsub("1982", "1981", x = .)

    names(nums) <- NULL

    cols <- dirty_xls[2,] %>%
      t() %>%
      as.vector() %>%
      .[-1] %>%
      trimws("both") %>%
      paste(nums, sep = "_")

    df_colnames <- c("country_name", cols)

    dirty_xls %<>%
      setNames(df_colnames) %>%
      .[-1:-2,]

    dirty_xls <- reshape2::melt(dirty_xls,
                                id.vars = "country_name", variable.name = "var_year",
                                value.name = "fh_score") %>%
      tidyr::separate(var_year, c("indicator", "year"), sep = "_") %>%
      dplyr::filter(fh_score != "-") %>%
      reshape2::dcast(country_name + year ~ indicator, value.var = "fh_score") %>%
      dplyr::mutate_at(dplyr::vars(c("CL", "PR")), as.numeric)
  }) %>%
    dplyr::bind_rows() %>%
    setNames(c("country_name", "year", "e_fh_cl", "e_fh_pr", "e_fh_status")) %>%
    dplyr::mutate(e_fh_status = dplyr::case_when(
      grepl("F ", e_fh_status) ~ 1,
      e_fh_status == "F" ~ 1,
      grepl("PF", e_fh_status) ~ 2,
      grepl("NF", e_fh_status) ~ 3
    ))

  fh_df[fh_df$country_name == "South Africa" & fh_df$year == 1972, "e_fh_cl"] <- 3
  fh_df[fh_df$country_name == "South Africa" & fh_df$year == 1972, "e_fh_pr"] <- 2
  fh_df[fh_df$country_name == "South Africa" & fh_df$year == 1972, "e_fh_status"] <- 1


  fht_df <- fh_df %>%
    dplyr::mutate(country_id = dplyr::case_when(
      grepl("Brazzaville", country_name) ~ 112,
      grepl("Kinshasa", country_name) ~ 111,
      grepl("d'Ivoire", country_name) ~ 64,
      grepl("Germany, E", country_name) ~ 137,
      grepl("Germany, W", country_name) ~ 77,
      grepl("United States", country_name) ~ 20,
      grepl("USSR", country_name) ~ 11,
      grepl("Vietnam, N", country_name) ~ 34,
      grepl("Vietnam, S", country_name) ~ 35,
      grepl("Yemen, N", country_name) ~ 14,
      grepl("Yemen, S", country_name) ~ 23,
      grepl("Yugoslavia ", country_name) ~ 198,
      grepl("^Gaza Strip$", country_name) ~ 138,
      grepl("West Bank", country_name) ~ 128,
      grepl("Palestinian", country_name) ~ 128
    )) %>%
    dplyr::filter(!is.na(country_id)) %>%
    dplyr::bind_rows({dplyr::inner_join(fh_df,
                                        dplyr::filter(mtable, country_id != 18), by = "country_name")}) %>%
    dplyr::mutate(year = as.numeric(year)) %>%
    dplyr::semi_join(country_unit, by = c("country_id", "year")) %>%
    dplyr::select(country_id, dplyr::everything(), -country_name) %>%
    dplyr::distinct()

  return(fht_df)
}

przeworski <- function(file_name, mtable_list) {
  com_df <- mtable_list[[match("com_df", names(mtable_list))]]
  mtable <- mtable_list[[match("mtable", names(mtable_list))]]

  przew <- read_file(file_name) %>%
    dplyr::select(country_name = PIPE_country, ccode = PIPE_cowcodes, country_number, year,
                  e_coups = coups, e_legparty = legparty)
  to_delete <- is.na(przew[,4:5]) %>% apply(1, all)
  przew_nona <- przew[!to_delete,] %>%
    dplyr::mutate(id = 1:nrow(.))
  przew1 <- przew_nona %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 300 & country_name == "Austria-Hungary (Austria)" ~ 305,
      grepl("Zaire", country_name) ~ 490,
      grepl("Swaziland", country_name) ~ 572,
      grepl("Brazzaville", country_name) ~ 484,
      grepl("^Cote", country_name) ~ 437,
      grepl("United States", country_name) ~ 2,
      grepl("Korea, S", country_name) ~ 732,
      grepl("Korea, N", country_name) ~ 731,
      grepl("Russian Federation", country_name) ~ 365,
      country_name == "Austria-Hungary (Hungary)" ~ 310,
      grepl("Serbia", country_name) ~ 345,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::group_by(ccode, year) %>%
    dplyr::filter(country_number == max(country_number)) %>%
    dplyr::ungroup

  przew2 <- przew_nona %>%
    dplyr::mutate(country_name = dplyr::case_when(
      country_name == "Korea, South" ~ "Korea",
      grepl("Libyan", country_name) ~ "Libya",
      grepl("East Timor", country_name) ~ "Timor-Leste",
      grepl("Macedonia", country_name) ~ "North Macedonia",
      grepl("gran colombia", country_name, ignore.case = TRUE) & year < 1824 ~ "Colombia",
      TRUE ~ country_name
    )) %>%
    dplyr::filter(!id %in% przew1$id) %>%
    dplyr::inner_join(com_df, by = "country_name")

  przew_df <- dplyr::bind_rows(przew1, przew2)

  coups_df <- dplyr::select(przew_df, -e_legparty) %>%
    dplyr::filter(!is.na(e_coups)) %>%
    dplyr::arrange(country_id, year, dplyr::desc(e_coups)) %>%
    dplyr::distinct(country_id, year, e_coups, .keep_all = TRUE)

  legp_df <- dplyr::select(przew_df, -e_coups) %>%
    dplyr::filter(!is.na(e_legparty)) %>%
    dplyr::arrange(country_id, year, dplyr::desc(e_legparty)) %>%
    dplyr::distinct(country_id, year, e_legparty, .keep_all = TRUE) %>%
    dplyr::select(country_id, year, e_legparty)

  fin_przew <- dplyr::full_join(coups_df, legp_df, by = c("country_id", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -id, -country_name, -country_number, -ccode, -country_text_id)

}

polity <- function(full_name, mtable) {
  pol_df <- read_file(full_name) %>%
    dplyr::select(ccode, scode, country, year, polity, polcomp, democ, polity2, autoc) %>%
    setNames(c("ccode", "iso3", "country_name", "year", "e_p_polity", "e_polcomp", "e_democ",
               "e_polity2", "e_autoc"))

  polity_df <- pol_df %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 255 & year == 1990 ~ 260,
      ccode == 678 & year == 1990 ~ 679,
      ccode == 89 ~ 90,
      ccode == 99 ~ 100,
      ccode == 342 ~ 345,
      grepl("Yugosla", country_name) ~ 345,
      grepl("Monteneg", country_name) ~ 341,
      grepl("Kosovo", country_name) ~ 347,
      ccode == 364 ~ 365,
      grepl("Sudan-North", country_name) ~ 625,
      grepl("South Sudan", country_name) ~ 626,
      ccode == 529 ~ 530,
      ccode == 769 ~ 770,
      ccode == 818 ~ 816,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::arrange(country_id, year) %>%
    dplyr::select(country_id, everything(), -ccode, -iso3, -country_name) %>%
    dplyr::arrange(country_id, year) %>%
    dplyr::distinct(country_id, year, .keep_all = TRUE)
  return(polity_df)
}

clio <- function(full_name, mtable) {
  clio <- read_file(full_name, sheet = 2)
  vname <- dplyr::case_when(grepl("Internal", basename(full_name)) ~ "e_miinterc",
                            grepl("International", basename(full_name)) ~ "e_miinteco",
                            grepl("AverageYearsofEducation", basename(full_name)) ~ "e_peaveduc",
                            grepl("FemalelifeexpectancyatBirth", basename(full_name)) ~ "e_pefeliex",
                            grepl("Inflation", basename(full_name)) ~ "e_miinflat",
                            grepl("TotalPopulation", basename(full_name)) ~ "e_mipopula",
                            grepl("TotalUrbanPopulation", basename(full_name)) ~ "e_miurbpop",
                            TRUE ~ NA_character_
  )

  clio_df <- setNames(clio, c(c("numeric_code", "country_name", "year"), vname)) %>%
    dplyr::arrange(numeric_code, year) %>%
    dplyr::inner_join(mtable[, c("country_id", "year", "numeric_code")], by = c("numeric_code", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -numeric_code, -country_name)

  return(clio_df)
}

uds <- function(full_name, mtable) {
  pemst_df <- read_file(full_name) %>%
    dplyr::select(ccode = cowcode, country_name = country, year,
                  e_uds_mean = mean, e_uds = median, e_uds_pct025 = pct025,
                  e_uds_pct975 = pct975) %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 260 & year > 1990 ~ 255,
      grepl("Yemen North", country_name) & year > 1989 ~ 679,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -country_name, -ccode)
  return(pemst_df)
}

radio <- function(full_name, mtable) {
  comhob_df <- read_file(full_name, header = TRUE) %>%
    dplyr::select(country_name, year, e_radio_n = radio) %>%
    dplyr::filter(!is.na(e_radio_n)) %>%
    dplyr::mutate(country_name = dplyr::case_when(
      country_name == "Burma" ~ "Burma/Myanmar",
      grepl("Slovak ", country_name) ~ "Slovakia",
      grepl("South Vietnam", country_name) ~ "Republic of Vietnam",
      grepl("United States", country_name) ~ "United States of America",
      grepl("Venezuala", country_name) ~ "Venezuela",
      TRUE ~ country_name
    )) %>%
    dplyr::inner_join(dplyr::distinct(mtable[,c("country_id", "country_name")]), by = "country_name") %>%
    dplyr::select(country_id, year, dplyr::everything(), -country_name)
  return(comhob_df)
}

habmen <- function(full_name, mtable) {
  habmen <- read_file(full_name, sheet = 2) %>%
    dplyr::select(hmccode, cnamehabmen, year, Civil_War, Total_Fuel_Income_PC, Total_Oil_Income_PC,
                  Total_Resources_Income_PC) %>%
    setNames(c("ccode", "cname", "year", "e_civil_war", "e_total_fuel_income_pc",
               "e_total_oil_income_pc", "e_total_resources_income_pc"))
  to_delete <- is.na(habmen[,4:7]) %>% apply(1, all)
  habmen_nona <- habmen[!to_delete,]
  habmen_df <- habmen_nona %>%
    dplyr::mutate(ccode = dplyr::case_when(
      (ccode == 255 & year > 1948) & (ccode == 255 & year < 1991) ~ 260,
      ccode %in% c(342, 347) ~ 345,
      ccode == 679 & year < 1990 ~ 678,
      ccode == 818 ~ 816,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[, c("ccode", "country_id", "year")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -ccode, -cname)
  return(habmen_df)
}

cowec <- function(full_name, mtable) {
  cow_econom <- read_file(full_name) %>%
    dplyr::select(ccode, statename, year, imports, exports) %>%
    setNames(c("ccode", "country_name", "year", "e_cow_imports", "e_cow_exports"))

  to_delete <- is.na(cow_econom[,4:5]) %>% apply(1, all)
  cowec_nona <- cow_econom[!to_delete,]
  cowec_df <- cowec_nona %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 300 ~ 305,
      (ccode == 255 & year > 1959) & (ccode == 255 & year < 1991) ~ 260,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[, c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -ccode, -country_name)
  return(cowec_df)
}

boix <- function(full_name, mtable) {
  boix <- read_file(full_name) %>%
    dplyr::select(country_name = country, ccode, iso3 = abbreviation, year,
                  e_boix_regime = democracy,
                  e_democracy_breakdowns = democracy_breakdowns,
                  e_democracy_omitteddata = democracy_omitteddata,
                  e_democracy_trans = democracy_trans)

  to_delete <- is.na(boix[,5:8]) %>% apply(1, all)
  boix_nona <- boix[!to_delete,]

  boix_df <- boix_nona %>%
    dplyr::mutate(ccode = dplyr::case_when(
      ccode == 89 ~ 90,
      ccode == 347 & dplyr::between(year, 1992, 2005) ~ 345,
      ccode == 99 ~ 100,
      ccode == 347 & year < 2006 ~ 341,
      ccode == 529 ~ 530,
      ccode == 99 ~ 100,
      ccode == 769 ~ 770,
      (ccode == 342 & year != 1991) | (ccode == 342 & year != 2006) ~ 345,
      ccode == 364 ~ 365,
      ccode == 818 ~ 816,
      TRUE ~ as.numeric(ccode)
    )) %>%
    dplyr::inner_join(mtable[,c("ccode", "year", "country_id")], by = c("ccode", "year")) %>%
    dplyr::select(country_id, year, dplyr::everything(), -country_name, -ccode, -iso3) %>%
    dplyr::arrange(country_id, year)

  return(boix_df)
}

gdppop <- function(full_name, mtable, country_unit) {
  gdppop_df <- read_file(full_name)

  stopifnot(c("indicator", "mean", "sd") %in% names(gdppop_df))
  dt <- dplyr::select(gdppop_df, gwno, year, indicator, mean, sd) %>%
    dplyr::filter(grepl("latent", indicator)) %>%
    dplyr::mutate(indicator = gsub("latent_", "", indicator)) %>%
    data.table::as.data.table()

  dt <- data.table::dcast(dt, gwno + year ~ indicator,
                          value.var = c("mean", "sd"))

  colnames(dt) <- gsub("(mean_|sd_)(.*)", "\\2_\\1", names(dt)) %>%
    gsub("^_|mean_", "", x = .) %>%
    gsub("_$", "", x = .) %>%
    gsub("(gdp|pop)", "e_\\1", x = .)

  mtable <- dplyr::select(mtable, country_id, year, gwno = ccode)

  gw_cnames <- dplyr::distinct(mtable, gwno, country_id)

  fariss_dt <- dplyr::left_join(dt, gw_cnames, by = "gwno") %>%
    dplyr::semi_join(country_unit, by = c("country_id", "year"))

  dups <- dplyr::group_by(fariss_dt, country_id,year) %>%
    dplyr::tally(sort = TRUE) %>%
    dplyr::filter(n > 1) %>%
    dplyr::select(-n)

  non_dups <- dplyr::anti_join(fariss_dt, dups)

  dup_clean <- dplyr::semi_join(fariss_dt, dups) %>%
    dplyr::semi_join(mtable, by = c("gwno", "year"))

  fin_gdppop_df <- dplyr::bind_rows(non_dups, dup_clean) %>%
    dplyr::select(country_id, year, dplyr::matches("^e_gdp"),
                  dplyr::matches("^e_gdpp"), dplyr::matches("^e_pop")) %>%
    dplyr::arrange(country_id, year) %>%
    dplyr::mutate(dplyr::across(dplyr::starts_with("e_"),
                                ~round(.x, digits = 5))) %>%
    as.data.frame()

  return(fin_gdppop_df)
}

bnr <- function(full_name, mtable) {

  bnr_df <- read_file(full_name, header = TRUE) %>%
    select(numeric_code = ccode, year, bnr_dem) %>%
    mutate(numeric_code = case_when(
      numeric_code == 991 ~ 250,
      numeric_code == 992 ~ 458,
      numeric_code == 736 ~ 729,
      numeric_code == 200 ~ 203,
      numeric_code == 280 ~ 276,
      TRUE ~ as.numeric(numeric_code)
    )) %>%
    dplyr::inner_join(mtable[, c("numeric_code", "country_id", "year")],
                      by = c("numeric_code", "year")) %>%
    dplyr::select(country_id, year, e_bnr_dem = bnr_dem)

  return(bnr_df)
}

ti_cpi <- function(full_name, mtable) {
  ti <- read_file(full_name, sheet = 2)
  colnames(ti) <- ti[1,]
  colnames(ti)[grepl("Country", colnames(ti))] <- "country_name"
  ti <- ti[-1,] %>%
    dplyr::select(country_name, iso3 = ISO3, dplyr::matches("CPI")) %>%
    reshape2::melt(id.vars = c("country_name", "iso3"),
                   variable.name = "year", value.name = "e_ti_cpi"
    ) %>%
    dplyr::mutate(year = gsub("cpi score ", "", tolower(year))) %>%
    dplyr::mutate_at(vars(c("year", "e_ti_cpi")), as.numeric)

  ti_df <- ti %>%
    mutate(iso3 = case_when(
      iso3 == "KSV" ~ "XKX",
      TRUE ~ iso3
    )) %>%
    inner_join(mtable[,c("iso3", "country_id", "year")], by = c("iso3", "year")) %>%
    select(country_id, everything(), -country_name, -iso3) %>%
    arrange(country_id, year)
  return(ti_df)
}

wb_pop <- function(full_name, mtable) {
  stopifnot("WDI" %in% rownames(installed.packages(lib.loc = .libPaths()[1])))

  wdi <- WDI::WDI(country= "all", indicator = "SP.POP.TOTL") %>%
    setNames(c("iso2", "country_name", "e_" %^% full_name, "year"))

  wdi_df <- dplyr::inner_join(wdi, mtable[,c("iso2", "country_id", "year")], by = c("iso2", "year")) %>%
    dplyr::filter(!is.na(e_wb_pop)) %>%
    dplyr::arrange(country_id, year) %>%
    dplyr::select(country_id, year, dplyr::everything(), -iso2, -country_name)

  return(wdi_df)
}

#' Load and clean external data
#'
#' Read in the data, clean it and assign V-Dem country_id
#'
#' @param file_name Full or relative path to the file
#'
#' @param con PostgreSQL connection to the database with external data
#'
#' @details Nothing more, nothing less than just reading the data, guessing the source,
#' and matching cleaning function and merging table for the source. It is not
#' vectorised. Before using make sure that your .pgpass file exists and has all
#' relevant fields (the function connects to V-Dem data database to extract information
#' about countries and country units).
#'
#' @return data.frame with V-Dem country_id, year, and target variable(s).
#'
#' @examples
#' \dontrun{load_ext_source(list.files("~/Documents/edata/2021/upd/", full.names = TRUE)[1])}
#'
#' @export
load_ext_source <- function(file_name = "wb_pop", con) {
  data_key <- guess_source_by_file_name(file_name)
  stopifnot(length(data_key) == 1,
            !is.na(data_key))

  tbl_name <- choose_mtable(data_key)

  if (tbl_name %in% c("all_df") | data_key %in% c("fh", "gapminder", "gdppop")) {

    if (nchar(Sys.getenv("ROOT_DIR")) < 1) {stop("Set ROOT_DIR environment variable!")}

    cu <- load_country_unit() %>%
      dplyr::select(country_id, year)
  }

  if (tbl_name %in% c("all_df")) {
    all_mtables <- lapply(c("iso", "cow", "gw"), function(tbl) {
      DBI::dbGetQuery(con, paste0("select * from mtable.", tbl, ";")) %>%
        dplyr::select(country_id, country_name)
    }) %>%
      dplyr::bind_rows()

    # I don't really like this part but let's just hope that it works...
    # don't need to invoke it too often luckily
    cntr <- load_country() %>%
      dplyr::select(country_id, country_name = name)

    mtable <- dplyr::bind_rows(all_mtables, cntr) %>%
      dplyr::distinct() %>%
      dplyr::semi_join(cu, by = "country_id")

    if (tbl_name == "mtable_list") {
      mtable_list <- list(com_df = mtable,
                          mtable = DBI::dbGetQuery(con, "select * from mtable.cow;"))
    }

  } else {
    mtable <- DBI::dbGetQuery(con, paste0("select * from mtable.", tbl_name, ";"))
  }

  func_name <- get(data_key)
  f <- function(...) {
    out <- tryCatch(
      {message(paste("Processing source:", data_key))
        func_name(...)},
      error = function(cond) {
        message(paste("Source error:", data_key))
        message(cond)
        return(cond)
      })
    return(out)
  }

  if (data_key %in% c("fh", "gapminder", "gdppop")) {
    res <- f(file_name, mtable, cu)
  } else if (data_key == "przeworski") {
    res <- f(file_name, mtable_list)
  } else {
    res <- f(file_name, mtable)
  }

  return(res)
}

#' @export
load_qtable <- function() {
  read_file(file.path(Sys.getenv("ROOT_DIR"), "refs", "question_table.rds"))
}

#' @export
load_country <- function() {
  read_file(file.path(Sys.getenv("ROOT_DIR"), "refs", "country_table.rds"))
}

#' @export
load_country_unit <- function() {
  read_file(file.path(Sys.getenv("ROOT_DIR"), "refs", "country_unit.rds"))
}

#' @export
load_codebook <- function() {
  read_file(file.path(Sys.getenv("ROOT_DIR"), "refs", "codebook.rds"))
}

#' @export
load_ptable <- function() {
  read_file(file.path(Sys.getenv("ROOT_DIR"), "refs", "party_table.rds"))
}

#' @export
load_ds <- function(cy = TRUE) {
  if (cy) {
    read_file("~/data/datasets/v10/Country_Year_V-Dem_Full+others_R_v10/V-Dem-CY-Full+Others-v10.rds")
  } else {
    read_file("~/data/datasets/v10/Country_Date_V-Dem_R_v10/V-Dem-CD-v10.rds")
  }
}



#' @export
mm_submit_tetralith_job <- function(variable, iter, timeout = "60:00:00",
                                    directory = Sys.getenv("MM_DIR")) {
  system("ssh tetralith " %^%
           "'cd " %^% directory %^% "; " %^%
           "export LOGDIR=" %^% directory %^% "/logs/; " %^%
           "export VARIABLENAME=" %^% variable %^% "; " %^%
           "export ITER=" %^% iter %^% "; " %^%
           "export R_SEED=0; " %^%
           "export STAN_SEED=0; " %^%
           "./scripts/zbatch " %^%
           "-t " %^% timeout %^%
           " scripts/mm_batch.sh " %^% variable %^%
           " '")
  info("Submitted " %^% variable %^% " with " %^% iter %^% " iterations.")
}


#' @export
bfa_submit_tetralith_job <- function(index,
                                     timeout = "24:00:00",
                                     directory = Sys.getenv("BFA_DIR"),
                                     script = "R/bfa.R",
                                     hpc = "tetralith") {
  system("ssh " %^% hpc %^% " " %^%
           "'cd " %^% directory %^% "; " %^%
           "export LOGDIR=" %^% directory %^% "/logs/; " %^%
           "export VARIABLENAME=" %^% index %^% "; " %^%
           "./scripts/zbatch " %^%
           "-t " %^% timeout %^%
           " scripts/bfa_batch.sh " %^% script %^% "'")
  info("Submitted " %^% index)
}

#' @export
mm_read_log <- function(logpath, local_dir = FALSE) {
  if (!local_dir) {
    stopifnot(is_path_mounted())
  }

  print(logpath)
  f <- readLines(logpath)
  if (any(grepl("file.exists(INFILE) is not TRUE", f, fixed = T)))
    return(NULL)

  # Create data.frame
  df <- data.frame(job_id = gsub("^.*[_](.*?)[.]out$", "\\1", basename(logpath)),
                   stringsAsFactors = F)

  # if there is an early error before we can parse any data we still want to
  # know that there was an error
  if (any(grepl("Error", f)) & !any(grepl("START", f))) {
    df$status <- "error"
    df$logfile <- logpath
    return(df)
  }

  df$name <- stringr::str_extract(f, "NAME[:]\\s.*$") %>% na.omit %>%
    gsub("NAME: ", "", ., fixed = T)
  df$iter <- stringr::str_match(f, "ITER[:]\\s\\d+") %>% na.omit %>%
    gsub("ITER: ", "", ., fixed = T)
  df$infile <- stringr::str_extract(f, "INFILE[:]\\s.*$") %>% na.omit %>%
    gsub("INFILE: ", "", ., fixed = T)
  df$outdir <- stringr::str_extract(f, "OUTDIR[:]\\s.*$") %>% na.omit %>%
    gsub("OUTDIR: ", "", ., fixed = T)
  df$start <- stringr::str_extract(f, "START[:]\\s.*$") %>% na.omit %>%
    gsub("START: ", "", ., fixed = T)
  df$r_seed <- stringr::str_extract(f, "R_SEED[:]\\s.*$") %>% na.omit %>%
    gsub("R_SEED: ", "", ., fixed = T)
  df$stan_seed <- stringr::str_extract(f, "STAN_SEED[:]\\s.*$") %>% na.omit %>%
    gsub("STAN_SEED: ", "", ., fixed = T)
  df$logfile <- logpath
  df$status <- dplyr::case_when(
    any(grepl("Convergence failed", f, fixed = TRUE)) ~ "failed",
    any(grepl("(Bulk|Tail) Effective Samples Size [(]ESS[)] is too low", f)) &
      any(grepl("Done with", f)) ~ "warning",
    any(grepl("Done with", f)) ~ "converged",
    any(grepl("Error", f)) ~ "error",
    any(grepl("Chain", f[length(f)])) ~ "running",
    any(grepl("TIME LIMIT", f)) ~ "timed_out",
    any(grepl("CANCELLED", f)) ~ "cancelled",
    TRUE ~ "other")
  if(length(stringr::str_extract(f, "END[:]\\s.*$") %>% na.omit) > 0) {
    df$end <-
      stringr::str_extract(f, "END[:]\\s.*$") %>%
      na.omit %>%
      gsub("END: ", "", ., fixed = T) %>%
      .[1]
  }
  if (df$status == "cancelled") {
    df$end <-
      stringr::str_extract(f, "CANCELLED\\sAT\\s.*$") %>%
      na.omit %>%
      gsub("CANCELLED AT ", "", ., fixed = TRUE) %>%
      gsub(" ***", "", ., fixed = TRUE) %>%
      gsub("T", " ", ., fixed = TRUE)

  }
  df %<>% dplyr::select(job_id, name, iter, status, start, dplyr::everything())
  return(df)
}

#' @export
mm_log_table <- function(LOG_PATH, varname) {
  ll <- list.files(LOG_PATH, full.names = T, pattern = paste0(varname, "-")) %>%
    lapply(mm_read_log) %>%
    dplyr::bind_rows() %>%
    dplyr::arrange(name)
  return(ll)
}

#' @export
mm_log_table_all <- function(LOG_PATH) {
  ll <- list.files(LOG_PATH, full.names = T)
  dplyr::bind_rows(lapply(ll, mm_read_log)) %>% dplyr::arrange(name)
}

#' @export
make_slurm_fname <- function(file_name) {
  slurm_job_id <- Sys.getenv("SLURM_JOB_ID")
  slurm_node_id <- Sys.getenv("SLURM_JOB_NODELIST")
  slurm_name <- paste(slurm_job_id, slurm_node_id, file_name, sep = "_")
  return(slurm_name)
}

#' @export
submit_accountability <- function(v, directory = Sys.getenv("ACC_DIR"),
                                  timeout = "72:00:00", script = "scripts/submit.sh",
                                  hpc = "tetralith") {

  stopifnot(!is.null(v), length(v) == 1)
  if (hpc == "tetralith") {
    ssq <- shQuote("projinfo -C | grep snic | awk '{print $3}'")
    account <- system(paste0("ssh ", hpc, " ", ssq), intern = TRUE)
  }
  if (hpc == "kebnekaise")
    account <- "SNIC2019-3-154"

  logfile <- paste0(directory, "/logs/", v, "-", Sys.Date(), "_%A_%N.out")
  rscript <- paste0(directory, "/R/", v, ".R")


  system(paste0("ssh ", hpc, " 'cd ", directory,
                "; export var=", v,
                "; export rscript=", rscript,
                "; sbatch -J ", v, " -A ", account," -o ", logfile,
                " -e ", logfile, " --time=", timeout,
                " --mail-type=FAIL -N 1 --exclusive ", script, "'"))
}

#' @export
squeue_table <- function(USER = "x_johvo") {
  system(paste0("ssh tetralith \"squeue -u ", USER,
                " --format='%.18i %.9P %.20j %.8u %.2t %.10M %.6D %R'\""),
         intern = TRUE) %>%
    strsplit(., " ") %>%
    lapply(function(v) {
      v <- v[v != ""]
      data.frame(
        job_id =  v[1],
        hpc = v[2],
        var_short = v[3],
        user = v[4],
        run_status = v[5],
        run_time = v[6],
        nodes = v[7],
        nodelist_reason = v[8])
    }) %>% dplyr::bind_rows(.) %>% .[-1, ]
}

#' @export
mm_summary <- function(df_logs) {
  df_logs %>%
    dplyr::group_by(name) %>%
    dplyr::summarize(status = dplyr::case_when(
      any(status == "converged") ~ "converged",
      any(status == "warning") ~ "warning",
      any(status == "running") ~ "running",
      any(status == "other") ~ "other",
      any(status == "failed") ~ "failed",
      any(status == "timed_out") ~ "timed_out",
      TRUE ~ "weird"), .groups = "drop") %>%
    dplyr::arrange(name, status) %$%
    table_(status)
}

#' Check for v-dem date columns and add/modify them where applicable.
#'
#' Checks for the given data.frame if the "year" column exists and if it is of type numeric.
#' If it does not exist it is created from the "historical_date" column and in any case set
#' to type numeric.
#' The function also checks for a "historical_date" column and creates it from the "year" column if
#' necessary and makes sure it is of type Date.
#'
#' @param df A v-dem data.frame in wide format.
#'
#' @return A data.frame similar to the input, but with date columns adjusted.
#'
#' @export
add_date_cols <- function(df) {
  if("year" %in% colnames(df)) {
    if(class(df$year) != "numeric") df$year <- as.numeric(df$year)
  } else df$year <- as.numeric(substr(df$historical_date, 1, 4))
  if("historical_date" %in% colnames(df)) {
    if(class(df$historical_date) != "Date")
      df$historical_date <- as.Date(df$historical_date)
  } else df$historical_date <- as.Date(paste0(df$year, "-12-31"))
  df
}

#' @export
add_country_cols <- function(df, country) {
  if (all(c("country_text_id", "country_id") %in% names(df)))
    return(as.data.frame(df, stringsAsFactors = F))
  stopifnot(any(c("country_text_id", "country_id") %in% names(df)))


  if("country_id" %in% names(df)) {
    return(dplyr::left_join(df, dplyr::select(country, country_id, country_text_id),
                            by = c("country_id")) %>% as.data.frame(stringsAsFactors = F))
  }

  if ("country_text_id" %in% names(df)) {
    return(dplyr::left_join(df, dplyr::select(country, country_id, country_text_id),
                            by = c("country_text_id")) %>% as.data.frame(stringsAsFactors = F))
  }
  stop("We should not hit this case")
}


#' Translate identifiers
#'
#' \code{trans} translates a vector of identifiers from one format to
#' another according to a given translation table (\emph{e.g.},
#' translating question IDs to question name).
#'
#' @param v Vector of any type.
#' @param to Character. Corresponding identifier format to translate
#'     our vector \code{v} to.
#' @param ttable Translation table. Must be a \code{data.frame}
#'     containing the columns specified by \code{to} and \code{by}
#' @param by Character. Column key for translation.
#'
#' @section Warning: This function is meant to serve as a constructor
#'     for identifier specific translation functions --- for example,
#'     see the function \code{\link{to_qids}}. It's not
#'     particularly useful or inuitive for direct use.
#'
#' @examples
#' \dontrun{
#' # Given a vector of question IDs saved to qids and we want the
#' # corresponding tag names using the translation table `qtable`.
#' trans(qids, to = "name", ttable = qtable, by = "question_id")
#' }
#'
#' @family translation helper functions
#' @seealso \code{\link{to_qids}} for question IDs,
#'     \code{\link{to_qnames}} for question names,
#'     \code{\link{to_cids}} for country IDs, \code{\link{to_cnames}}
#'     for country names.
#'
#' @export
trans <- function(v, to = NULL, ttable = NULL, by = NULL) {
  for (x in c("to", "ttable", "by"))
    if (is.null(eval(substitute(x))))
      stop("Missing argument: " %^% x)

  columns <- colnames(ttable)
  if (!by %in% columns | !to %in% columns)
    stop("Missing `to` or `by` column in translation table")

  if (any(!v %in% ttable[[by]]))
    stop("Missing values in ttable from " %^% deparse(substitute(v)))

  ttable[[to]][match(v, ttable[[by]])]
}

#' Translation helper functions
#'
#' Convenience functions to translate several common identifiers at V-Dem.
#'
#' @param v \code{CharacterVector} or \code{NumericVector}
#' @param ttable Translation table. See \link{trans}.
#'
#' @details The listed helper functions are fairly rigid in their
#'     assumptions, especially in the case of assumed column names in
#'     the translation table.
#'
#'     It's worth noting that the function \code{to_qlabels} expects
#'     not the \code{question} table as \code{ttable}, but rather the
#'     \code{codebook} table, which contains the canonical short-form
#'     question description texts. Further, it includes a call to
#'     \code{\link{get_root}} so that it can conveniently be called on
#'     the columns of the final dataset.
#'
#' @examples
#' \dontrun{
#' tags <- c("v2clacfree", "v2elpaidig")
#' qids <- to_qids(tags, qtable)
#' to_qnames(qids)
#' }
#'
#' @seealso \code{\link{trans}}
#' @name trans_helpers
NULL

#' @describeIn trans_helpers Translate country text IDs to country IDs
#' @export
to_cids <- function(v, ttable) {
  trans(v, to = "country_id", ttable = ttable, by = "country_text_id")
}

#' @describeIn trans_helpers Translate country text IDS to country names
#' @export
to_cnames <- function(v, ttable) {
  trans(v, to = "name", ttable = ttable, by = "country_text_id")
}

#' @describeIn trans_helpers Translate country IDs to country text IDs
#' @export
to_ctext_ids <- function(v, ttable) {
  trans(v, to = "country_text_id", ttable = ttable, by = "country_id")
}

#' @describeIn trans_helpers Translate question tag names to question IDs
#' @export
to_qids <- function(v, ttable) {
  trans(v, to = "question_id", ttable = ttable, by = "name")
}

#' @describeIn trans_helpers Translate question IDs to question tag names
#' @export
to_qnames <- function(v, ttable) {
  trans(v, to = "name", ttable = ttable, by = "question_id")
}

#' Front-fill an object
#'
#' S3 generic function that front-fills by carrying the last
#' observation forward. For DataFrames and Matrices, this is done
#' column-wise.
#'
#' @param x Object to front fill.
#'
#' @examples
#' v <- c(NA, 1, NA, 2, 2)
#' locf(v)
#'
#' df <- data.frame(x = c(1, NA, NA))
#' (out <- locf(df))
#'
#' # The original object should be preserved
#' identical(df, out)
#'
#' m <- matrix(1:6, 3, 2)
#' m[1, 2] <- NA
#'
#' # This should still be identical to m
#' locf(m)
#'
#' @family fill functions
#' @export
locf <- function(x) UseMethod("locf")

#' Interpolation
#'
#' S3 generic function that back fills an object if the last element
#' is the only non-missing observation. Otherwise, front filling by
#' carrying the last observation forward is done, similar to
#' \code{\link{locf}}. For DataFrames and Matrices, this is all done
#' column-wise.
#'
#' @param x Object to interpolate.
#'
#' @details The differences between \code{locf} and \code{interpolate}
#'     are frustratingly trivial; however, we need the
#'     \code{interpolate} functions in situations where the only
#'     observation is at the default date ("-12-31"), which should
#'     then represent the entire year.
#'
#'     For example, when conforming multiple country-date level
#'     variables, missingness introduced by merging should be first
#'     interpolated before being expanded so as to better reflect the
#'     observation at the default date representing the entire year,
#'     rather than the previous year's default date observation being
#'     carried forward until "-12-30".
#'
#' @examples
#' df <- data.frame(x = c(1, NA, 2),
#'                  y = as.Date(c("1900-12-31", "1901-10-12", "1902-12-31")))
#'
#' transform(df, x = interpolate(x))
#'
#' # For comparison purposes
#' transform(df, x = locf(x))
#'
#' @family fill functions
#' @export
interpolate <- function(x) UseMethod("interpolate")

#' Gap Index
#'
#' \code{create_idx} returns a grouping index as a numeric vector
#' denoting sequential dates, \emph{i.e.} groups separated by year
#' gaps. The resulting vector can be coerced to a factor for use with
#' \code{split} or \code{dplyr::group_by}.
#'
#' @param x Vector of years or Date objects.
#'
#' @details Where this is most useful is when we fill in missing
#'     observations and we want to make sure we never fill across year
#'     gaps. \code{create_idx} returns a grouping vector that can be
#'     used when splitting before filling.
#'
#'     The actual values of the returned vector are inconsequential
#'     and are only useful for identifying groups.
#'
#'     As an example, V-Dem does not code the occupation of Germany
#'     after WWII. To ensure that values prior to 1946 are not used to
#'     fill in missingness after 1949, the data should be split by
#'     gaps by creating an index column denoting the two groups.
#'
#' @examples
#' dates <- as.Date(c("1900-01-01", "1901-12-31", "1903-01-01"))
#' create_idx(dates)
#'
#' years <- c(1900, 1901, 1905, 1907)
#' create_idx(years)
#'
#' @export
create_idx <- function(x) UseMethod("create_idx")

#' @export
create_idx.default <- function(x) {
  if (any(is.na(x)))
    stop("Invalid input vector contained NA", call. = F)

  if (!is.numeric(x) | any(floor(log10(x)) + 1 != 4))
    stop("Invalid years", call. = F)

  cumsum(c(T, diff(x) > 1))
}

#' @export
create_idx.Date <- function(x) {
  if (any(is.na(x)))
    stop("Invalid input vector contained NA", call. = F)

  cumsum(c(T, diff(x) > 366))
}


#' @export
interpolate_vdem_style <- function(df, col, utable) {
  stopifnot(is.data.frame(df))
  stopifnot(c("historical_date", "year", "country_id") %in% names(df))
  stopifnot(!"fill_col" %in% names(df))

  out <- df %>%
    add_gap_idx(utable) %>%
    dplyr::group_by(country_id) %>%
    # interpolate gap_idx for historical years not in utable!
    # This should not interpolate into gaps, that is dangerous.
    dplyr::arrange(dplyr::desc(historical_date)) %>%
    dplyr::mutate(gap_idx = locf(gap_idx)) %>%
    dplyr::ungroup() %>%
    #{stopifnot(!anyNA(.$gap_idx))} %>%
    dplyr::group_by(country_id, year) %>%
    dplyr::arrange(country_id, historical_date) %>%
    dplyr::mutate(fill_col = interpolate(!!dplyr::sym(col))) %>%
    dplyr::group_by(country_id, gap_idx) %>%
    dplyr::arrange(country_id, historical_date) %>%
    dplyr::mutate(fill_col = locf(fill_col)) %>%
    dplyr::ungroup() %>%
    dplyr::select(-gap_idx) %>%
    as.data.frame(stringsAsFactors = F)
}



#' @export
interpolate_vdem_col <- function(df, col, utable) {
  stopifnot(is.data.frame(df))
  stopifnot(c("historical_date", "year", "country_id") %in% names(df))
  out <- interpolate_vdem_style(df, col, utable)
  out[[col]] <- out$fill_col
  out$fill_col <- NULL
  out
}

#' @export
fill_special_cols <- function(df, utable) {
  colu <- c("v2lgbicam", "v2exhoshog", "v2expathhs", "v2expathhg",
            "v2lgello", "v2lginello", "v2lgelecup", "v2lginelup",
            "v2exapup", "v2exapupap")
  lapply(colu, function(v) {
    if (v %in% names(df))
      df <<- interpolate_vdem_col(df, v, utable)
  }) %>% invisible

  df
}


#' @export
add_gap_idx <- function(df, utable) {
  stopifnot(c("year", "country_id") %in% names(df))
  stopifnot(!"gap_idx" %in% names(df))
  dplyr::left_join(df, dplyr::select(utable, country_id, year, gap_idx),
                   by = c("country_id", "year"))
}

#' @export
full_join_vdem <- function(df1, df2, ...) {

  stopifnot(is.data.frame(df1), is.data.frame(df2))
  if (nrow(df1) == 0)
    return(df2)
  if (nrow(df2) == 0)
    return(df1)

  cy_vars <- character(0)
  if ("country_id" %in% names(df1) & "country_id" %in% names(df2))
    cy_vars <- "country_id"
  if ("country_text_id" %in% names(df1) & "country_text_id" %in% names(df2))
    cy_vars <- c(cy_vars, "country_text_id")

  date_vars <- character(0)
  if ("historical_date" %in% names(df1) & "historical_date" %in% names(df2))
    date_vars <- "historical_date"
  if ("year" %in% names(df1) & "year" %in% names(df2))
    date_vars <- c(date_vars, "year")

  if (length(cy_vars) == 0 | length(date_vars) == 0)
    stop("Missing identifier column!")

  info("merging by " %^% paste(c(cy_vars, date_vars), collapse = ", "))

  dplyr::full_join(df1, df2, by = c(cy_vars, date_vars), ...) %>%
    as.data.frame(stringsAsFactors = F)
}


#' @export
full_join_vdem_tree <- function(ll, mc_cores = 10) {

  while (TRUE) {
    n <- length(ll)
    print(n)
    if (n %% 2 == 0) {
      ll <- parallel::mcMap(full_join_vdem, ll[1:(n/2)], ll[((n/2) + 1):n],
                            mc.cores = mc_cores, mc.preschedule = FALSE)
    } else {
      lll <- ll[2:length(ll)]
      ll <- c(ll[1],
              parallel::mcMap(full_join_vdem, lll[1:(n/2)], lll[((n/2) + 1):n],
                              mc.cores = mc_cores, mc.preschedule = FALSE))
    }
    if (length(ll) == 1)
      break()
  }

  ll[[1]]
}
#' @export
load_matrix <- function(m, drop.vignettes = TRUE) {
  stopifnot(is.matrix(m))
  if (isTRUE(drop.vignettes))
    m <- m[!is_vignette(rownames(m)),, drop = F]
  m
}
#' @export
meta <- function(obj, attribute_value = NULL) {
  v <- attr(obj, "meta_data")
  if (is.null(v)) {
    info("No meta data stored in this object.")
    return(NULL)
  }
  if (is.null(attribute_value))
    return(v)
  v[names(v) == attribute_value]
}

#' Evaluate an expression with substitution
#'
#' \code{evalMacro} takes an unevaluated expression and an environment
#' to first substitute the specified objects and then evaluate the
#' resulting expression. The function \code{\link{bquote}} is used for
#' substitution, see the help page for substitution syntax.
#'
#' @param expr Expression
#' @param env Environment used for substitution.
#'
#' @details We use \code{\link{bquote}} instead of
#'     \code{\link{substitute}} to force an explicit syntax
#'     highlighting which objects should be substituted. The resulting
#'     expression is then evaluated within the context of the parent
#'     environment (see: \code{\link{parent.frame}}).
#'
#' @examples
#' x <- 1
#' expr <- quote(.(a) + 1)
#'
#' evalMacro(expr, list(a = x))
#'
#' df <- data.frame(x = c(1, 2, 3))
#' transform(df, y = evalMacro(expr, list(a = x)))
#'
#' @export
evalMacro <- function(expr, env = parent.frame()) {
  x <- do.call(bquote, list(expr, env))
  eval(x, parent.frame())
}


#' Check if arguments are \code{identical}
#'
#' Given an initial function argument, \code{all_identical} loops
#' through the remaining arguments checking that they are
#' \code{\link{identical}}.
#'
#' @param ... Objects to check
#'
#' @return A single boolean indicating whether all of the provided
#'     arguments are identical to each other.
#'
#' @examples
#' all_identical(list("a", "b"), list("a", "b"))
#'
#' all_identical("Not", "Equal")
#'
#' @export
all_identical <- function(...) {
  if (missing(...))
    stop("Missing arguments", call. = F)

  args <- list(...)

  if (length(args) < 2)
    return(TRUE)

  bools <- logical(length(args) - 1)
  for (i in 2:length(args))
    bools[i - 1] <- identical(args[[1]], args[[i]])

  all(bools)
}

#' Set union for variable number of arguments
#'
#' \code{s_union} returns the unique elements from a set
#' \code{\link{union}} between all function arguments.
#'
#' @param ... Variable number of arguments of any type.
#'
#' @section Warning: The resulting output object will not inherit the
#'     user-defined attributes of the input objects.
#'
#'     Also, as a further note, input objects are expected to be of
#'     the same type and are therefore exposed to R's normal system of
#'     type coercion.
#'
#' @examples
#' s_union(letters[1:3], letters[2:4], letters[3:5])
#'
#' @export
s_union <- function(...) {
  if (missing(...))
    stop("Missing arguments", call. = F)

  args <- list(...)

  if (length(args) < 2)
    return(args[[1]])

  unique(do.call(c, args))
}

#' Copy column 900 times
#'
#' \code{make_900cols} returns the data frame ready for BFA.
#' The first column contains the identifiers.
#'
#' @param df Input data.frame that should contain the column of interest
#' and case identifiers: country_text_id and historical date
#'
#' @param var Variable to be copied 900 times
#'
#' @export
make_900cols <- function(df, var, interpolate = FALSE) {
  stopifnot(("historical_date" %in% names(df) | "country_text_id" %in% names(df)) & var %in% names(df))

  df <- df[, c("country_text_id", "historical_date", var)]
  df <- df[!grepl("^A_|^B_", df[["historical_date"]]),]

  if(interpolate) {
    df %<>%
      dplyr::group_by(country_text_id) %>%
      dplyr::arrange(historical_date) %>%
      dplyr::group_by(gap_idx = create_idx(historical_date), add = TRUE) %>%
      dplyr::mutate_at(dplyr::vars(var), locf) %>%
      dplyr::ungroup()
  }

  df %<>%
    dplyr::mutate(country_dates = paste(country_text_id, historical_date, sep = " "))

  df_no_na <- df[!is.na(df[, var]),]

  cnames <- c("", paste0("V", 1:900))

  df_copied <- df_no_na[, c("country_dates", var)] %>%
    cbind(., replicate(899, .[, var]))
  names(df_copied) <- cnames

  return(df_copied)
}
#' Process posteriors for exporting
#'
#' @param path File path to MM/BFA/Binary/HLI file with posteriors
#' @details Normally the posteriors are located in \code{super} (BFA, MM) or \code{posterior} (HLI) directories.
#' @export
get_posterior <- function(path) {
  vname <- basename(path) %>% gsub("_\\d+.rds", "", x = .)

  fl <- vbase::read_file(path)[[1]]

  posterior <- if (grepl("bfa|hli", path)) {
    fl[["thin_post"]]
  } else if (grepl("mm|binary", path)) {
    fl[["post.sample"]][["z"]]
  } else {stop("Doesn't match BFA/MM/HLI/Binary file path!")}

  posterior <- posterior[!grepl("[A|B]_", rownames(posterior)),]

  df <- cbind(
    country_text_id = gsub(pattern = "([A-Z]+) (\\d+-\\d+-\\d+)", replacement = "\\1", x = rownames(posterior)),
    historical_date = gsub(pattern = "([A-Z]+) (\\d+-\\d+-\\d+)", replacement = "\\2", x = rownames(posterior)),
    var_name = vname,
    data.frame(posterior), stringsAsFactors = FALSE)

  colnames(df) <- gsub("^X", "V", colnames(df))
  bool <- c(FALSE, FALSE, FALSE, rep(TRUE, ncol(posterior)))

  if (!grepl("mm|binary", path)) {
    df[, bool] <- lapply(df[, bool], qnorm)
  }

  df[, bool] <- round(df[, bool], 5)

  stopifnot(all(nchar(df[["country_text_id"]]) == 3))
  stopifnot(all(!is.na(df[, c("country_text_id", "historical_date")])))

  return(df)
}
#' @export
replace_matrix <- function(m, b, missing = NA) {
  m <- m * b
  is.na(m) <- m <= 0

  m
}

#' Generate offsets for two groups of coders
#'
#' Given a matrix of ratings in the wide format (each column is a
#' separate coder and each row is a separate country-date),
#' \code{offset_diff} generates offsets for those coders specified in
#' the logical matrix \code{target} by weighted mean difference.
#'
#' @param m A matrix in the V-Dem wide format.
#' @param target Logical matrix denoting target coder group.
#' @param weight Numeric matrix for weighted row means (typically
#'     coder submitted confidences).
#' @param min Minimum number of coders country-date (\emph{i.e.}, rows) for the
#'     non-target coders.
#'
#' @details This function is exclusively used to generate offset
#'     priors for the historical and "new" coders (\emph{i.e.}, those
#'     who've only coded 2005 - present). The offsets are generated by
#'     comparing the ratings of one of the aforementioned groups to
#'     the coders not flagged by the logical \code{target} matrix.
#'
#'     The \code{min} argument allows us to restrict the calculation
#'     of weighted mean difference to only those country-dates
#'     (\emph{i.e.}, rows) where we have at least some minimum numbers
#'     of non-target coders.
#'
#' @return Single numeric value that can be used to offset the ratings
#'     for all of the target coders.
#'
#' @examples
#' # Matrix of raw coder-level data with 3 coders where coder "a" will
#' # be our historical coder.
#' m <- matrix(1:9, 3, 3,
#'             dimnames = list(c("AFG 1899-01-01",
#'                               "AFG 1900-01-01",
#'                               "AFG 1901-01-01"),
#'                             letters[1:3]))
#'
#' # Logical matrix for our single historical coder
#' historical <- matrix(c(rep(TRUE, 3), rep(FALSE, 6)), 3, 3)
#'
#' # Confidences, for this example everyone is 100% confident
#' conf <- matrix(rep(1, 9), 3, 3)
#'
#' # Generate offsets for our single historical coder
#' offset_diff(m, historical, conf)
#'
#' @family prior functions
#'
#' @export
offset_diff <- function(m, target, weight, min = 1) {
  if (!all_identical(dim(m), dim(target), dim(weight)))
    stop("Invalid dimensions", call. = F)

  if (all(!target))
    return(0)

  old_coders <- replace_matrix(m, !target)
  offset_coders <- replace_matrix(m, target)

  old_coders[colSums(apply(old_coders, 1, function(x) !is.na(x))) < min, ] <- NA

  old_means <- weighted.rowMeans(old_coders, weight)
  offset_means <- weighted.rowMeans(offset_coders, weight)

  if (all(is.nan(old_means) | is.nan(offset_means)))
    return(0)

  mean(old_means - offset_means, na.rm = T)
}

#' Weighted Row Means
#'
#' Calculates the weighted row means for a complex, numeric, integer,
#' or logical matrix.
#'
#' @param x Matrix to be summarised rowwise by the weighted
#'     mean.
#' @param y Matrix of the same dimensions as x. Used as the
#'     weights for calculating the weighted mean of \code{x}.
#' @param na.rm Logical. Whether missing values should be removed.
#'
#' @return NumericVector the same length as \code{nrow(x)}.
#'
#' @seealso \code{\link{rowMeans}}
#' @family prior functions
#'
#' @export
weighted.rowMeans <- function(x, y, na.rm = T) UseMethod("weighted.rowMeans")

#' @export
weighted.rowMeans.matrix <- function(x, y, na.rm = T) {
  y[is.na(x)] <- NA

  rowSums(x * y, na.rm = na.rm) / rowSums(y, na.rm = na.rm)
}

#' Convert keys to an unordered balanced sequence
#'
#' Given a vector of \code{keys}, \code{to_seq} will return a
#' balanced sequence of numeric values from \code{min} to
#' \code{max}. The values will correspond to the unique alphabetical
#' ordering of \code{keys} applied to the original ordering of
#' \code{keys}.
#'
#' @param keys A vector of any type.
#' @param min Start value for the output sequence
#' @param max End value for the output sequence
#'
#' @details This function is used exclusively to set the priors for
#'     the vignettes. Currently, based on the order of the thresholds,
#'     we set the priors to be from -1.5 to 1.5.
#'
#'     Vignette thresholds can be sorted by any identifier as long as
#'     we can determine the proper order using \code{sort}.
#'
#' @examples
#' to_seq(c("a", "d", "c", "a"))
#'
#' @family prior functions
#'
#' @export
to_seq <- function(keys, min = -1.5, max = 1.5) {
  unique_keys <- sort(unique(keys))
  p <- seq(min, max, length.out = length(unique_keys))
  names(p) <- unique_keys

  stats::setNames(p[match(keys, unique_keys)], NULL)
}
#' Normalize historical \code{question_id}s
#'
#' Given a vector of \code{question_id}s, \code{normalize_qids}
#' replaces the historical \code{question_id}s with the analogous
#' contemporary \code{question_id}s where there's a match based on
#' \code{ttable}.
#'
#' @param ids NumericVector of \code{question_id}s.
#' @param ttable \code{question_id} translation table (\emph{e.g.},
#'     the question table).
#'
#' @details \code{normalize_qids} is fairly inflexible and is meant to
#'     work directly with the question table. Thus, \code{ttable}
#'     requires two columns: \code{name} and \code{question_id}. We
#'     determine whether an historical \code{question_id} has a
#'     matching contemporary \code{question_id} by checking the root
#'     tag --- the portion of the tag after removing the \code{v\\d}
#'     suffix.
#'
#' @section Warning: We are currently not checking whether matching
#'     historical and contemporary \code{question_id}s have the same
#'     \code{K} (\emph{i.e.}, number of answer categories). This is
#'     mostly because our information on \code{K} is fairly
#'     incomplete; plus, there are a number of variables such as
#'     \code{v3lgbicam} which diverge from contemporary and yet we
#'     still want to merge them together.
#'
#'     This is something that can be improved in the future.
#'
#' @examples
#' ttable <- data.frame(question_id = 1:3,
#'                      name = c("v2clacfree", "v3clacfree", "v3strenadm"),
#'                      stringsAsFactors = FALSE)
#'
#' normalize_qids(1:3, ttable)
#'
#' @export
normalize_qids <- function(ids, ttable) {
  if (is.null(ttable))
    stop("Missing translation table")

  tags <- trans(ids, "name", ttable, "question_id")
  roots <- sub("v3", "v2", tags)
  new_ids <- trans(roots, "question_id", ttable, "name")

  # ids[roots %in% ttable$name & roots %in% tags] <-
  #    trans(roots[roots %in% ttable$name & roots %in% tags], "question_id", ttable, "name")

  # assertion exception for v2lgbicam / v3lgbicam
  #ids_test <- ids
  #ids_test<- ifelse(ids_test == 1379,
  #                      595,
  #                      ids_test)
  #stopifnot(identical(trans(ids_test, "k", ttable, "question_id"),
  #                    trans(new_ids, "k", ttable, "question_id")))

  new_ids
}


#' Display country transformations
#'
#' Given a vector of \code{country_ids}s, \code{country_text_ids}, and
#' \code{country_names} returns all other available transformations.
#'
#' @param countries Character or numeric vector.
#' @param db database connection.
#'
#' @examples
#' \dontrun{
#' country_options(c(4,"USA", "South Korea"))
#' }
#' @export
country_trans <- function(v, db_internal = pg_connect("vdem_data"), full = FALSE) {
  if (!is.vector(v))
    stop("v is not a vector.")
  if (!(is.character(v) | is.numeric(v)))
    stop("Wrong vector type!")

  country <- dplyr::tbl(db_internal, "country") %>% dplyr::collect(n = Inf) %>%
    dplyr::rename(country_text_id = text_id, country_name = name) %>%
    untibble %>%
    dplyr::select(country_id, country_text_id, country_name) %>%
    dplyr::filter(!is.na(country_text_id), !grepl("*", country_name, fixed = TRUE))

  if (isTRUE(full))
    return(country)

  if (is.numeric(v))
    return(country[country$country_id %in% v, ])

  # We loop because we want the results to be in the same order
  out <- lapply(v, function(i) {
    if (grepl("^[[:digit:]]+$", i)) {
      if (!i %in% country$country_id)
        info(i %^% " not found.")
      return(country[country$country_id == as.numeric(i), ])
    }

    if (grepl("^[[:upper:]]+$", i)) {
      if (!i %in% country$country_text_id)
        info(i %^% " not found.")
      return(country[country$country_text_id == i, ])
    }

    if (!i %in% country$country_name)
      info(i %^% " not found.")

    return(country[grepl(i, country$country_name), ])

  }) %>% dplyr::bind_rows(.)

  DBI::dbDisconnect(db_internal)

  return(out)
}
#' Expand based on row.names
#'
#' \code{stretch} expands a matrix row-wise by a given character
#' vector of country-dates. For example, it can be used to expand a
#' country-date reduced matrix to the full time series.
#'
#' @param x Matrix to expand.
#' @param by CharacterVector of country-dates to expand by.
#' @param gaps Logical, whether to preserve gaps when expanding.
#' @param preserve.na Logical, whether to preserve NA from the original
#'     matrix, \code{x}.
#' @param interpolate Logical, whether to first interpolate each year
#'     before filling in missing values in the expanded matrix.
#'
#' @details Given a matrix, \code{x}, with country-date rownames and a
#'     character vector of country-dates that should be added
#'     (\emph{i.e.,} expanded to), \code{stretch} will output a matrix
#'     with \code{ncol(x)} columns and \code{length(union(by,
#'     rownames(x)))} rows. The rows shared between the output matrix
#'     and \code{x} will be filled in with the values from \code{x}
#'     before calling \code{\link{locf}}.
#'
#'     Missingness will be filled in by \code{country_text_id}, sorted
#'     by \code{historical_date}. If \code{gaps} is \code{TRUE}, gaps
#'     will be preserved such that if there is more than a 365 day
#'     difference between two observations, the last observation will
#'     not be carried forward.
#'
#'     When \code{preserve.na} is \code{TRUE}, \code{NA} in the
#'     original matrix, \code{x}, will be preserved and propagated in
#'     the output matrix.
#'
#'     If \code{interpolate} is \code{TRUE}, before calling
#'     \code{\link{locf}}, values in the output matrix will be first
#'     interpolated per country-year using the
#'     \code{\link{interpolate}} --- specifically, this means that if
#'     there's a single non-missing observation on "12-31", the year
#'     will first be backfilled.
#'
#' @examples
#' m <- matrix(1:2, 2, 1, dimnames = list(c("AFG 1790-12-31", "AFG 1791-12-31"),
#'                                        NULL))
#'
#' full_names <- c("AFG 1790-12-31", "AFG 1791-05-04",
#'                 "AFG 1791-12-31", "AFG 1795-12-31")
#'
#' stretch(m, full_names)
#'
#' # Expand with interpolation
#' stretch(m, full_names, interpolate = TRUE)
#'
#' # Ignore gaps
#' stretch(m, full_names, gaps = FALSE)
#'
#' @family fill functions
#' @export
stretch <- function(x, by, gaps = TRUE, rule_366 = TRUE, preserve.na = TRUE, interpolate = FALSE,
                    utable = NULL, party = FALSE, elecreg_cy = NULL) {UseMethod("stretch")}

#' @export
stretch.matrix <- function(x, by, gaps = TRUE, rule_366 = TRUE, preserve.na = TRUE,
                           interpolate = FALSE, utable = NULL, party = FALSE,
                           elecreg_cy = NULL) {
  assert_str(by, party)
  assert_str(rownames(x), party)

  if (setequal(rownames(x), by))
    return(x[order(rownames(x)),, drop = F])

  full_names <- union(by, rownames(x))
  full.ma <- matrix(NA, length(full_names), ncol(x), dimnames = list(full_names, colnames(x)))

  full.ma[match(rownames(x), full_names), ] <- x
  full.ma <- full.ma[sort(rownames(full.ma)),, drop = F]

  # If TRUE we preserve NA from `x` and carry it forward in the
  # full.ma matrix since we assume that it represents missingness
  # that we want retained. Unfortunately, we're running up against
  # the R type system here so we have no meaningful way to
  # distinguish NAs from expanding and NAs originally in `x`. As an
  # ugly hack, replace the NAs from `x` with Inf and convert back in
  # the end.
  if (isTRUE(preserve.na)) {
    b <- rowSums(is.na(x)) == ncol(x)

    if (any(b))
      full.ma[rownames(full.ma) %in% rownames(x)[b], ] <- Inf
  }

  factors <- rownames(full.ma) %>% sub(" \\d{4}-\\d{2}-\\d{2}$", "", x = .)
  dates <- rownames(full.ma) %>% get_date(party)

  if (isTRUE(gaps)) {

    if (rule_366) {
      gaps <- split(dates, factors) %>%
        lapply(create_idx) %>%
        unlist
      if (any(is.na(gaps)))
        stop("Unable to set gaps", call. = F)
      factors <- factors %^% gaps
    } else {
      if (is.null(utable))
        stop("utable is missing!")

      join_cols <- c("country_text_id", "year")

      gaps <-
        data.frame(country_text_id = rownames(full.ma) %>% get_text_id(party),
                   historical_date = rownames(full.ma) %>% get_date(party),
                   stringsAsFactors = F)

      if (party) {
        join_cols <- c("country_text_id", "party_id", "historical_date")
        gaps[["party_id"]] <- rownames(full.ma) %>% get_party_id
      }

      if (is.null(elecreg_cy)) {
        gaps <- gaps %>%
          dplyr::mutate(year = to_year(historical_date)) %>%
          dplyr::left_join(utable, by = join_cols) %>%
          dplyr::pull(gap_idx)
      } else {
        # We do not want to interpolate election specific mm variables
        # into regimes where v2x_elecreg is 0.
        utable_merged <- utable_join_elecreg_index(utable, elecreg_cy)
        gaps <- gaps %>%
          dplyr::mutate(year = to_year(historical_date)) %>%
          dplyr::left_join(utable_merged, by = join_cols) %>%
          dplyr::pull(combined_idx)
      }


      if (any(is.na(gaps)))
        stop("Unable to set gaps", call. = F)

      factors <- gaps
    }



  }

  if (isTRUE(interpolate)) {
    years <- to_year(dates)

    # We really should think about simplifying this
    full.ma <- by_split(full.ma, factors %^% years,
                        methods::getFunction("interpolate"))
    full.ma <- full.ma[order(rownames(full.ma)),, drop = F]
  }

  out <- by_split(full.ma, factors, locf)
  out[is.infinite(out)] <- NA
  out <- out[order(rownames(out)),, drop = F]

  return(out)
}


#' @export
mm_stretch_z_sample <- function(ll, utable) {
  stretch(load_matrix(ll[[1]]$post.sample$z),
          ll[[1]]$country_dates,
          rule_366 = TRUE,
          interpolate = TRUE,
          utable = utable)
}

#' @export
binary_stretch_z_sample <- function(ll, utable) {
  stretch(load_matrix(ll[[1]]$post.sample$z),
          ll[[1]]$country_dates,
          rule_366 = TRUE,
          interpolate = TRUE,
          utable = utable)
}

#' @export
bfa_stretch_z_sample <- function(ll, utable) {
  stretch(load_matrix(ll[[1]]$thin_post),
          ll[[1]]$country_dates,
          rule_366 = TRUE,
          interpolate = TRUE,
          utable = utable)
}

# Expects a named list of matrices and returns a named list of matrices

#' @export
stretch_combined <- function(ll, utable) {
  stopifnot(lapply(ll, is.matrix) %>% unlist)
  nn <- names(ll)
  combined_names <- lapply(ll, rownames) %>% unlist %>% unique %>% sort
  info(sprintf("Found %d combined country-dates", length(combined_names)))
  out <- Map(function(m, nam) {
    info("Stretching " %^% nam)
    stretch(m, combined_names, interpolate = T, utable = utable)
  }, m = ll, nam = nn)

  stopifnot({
    first_rownames <- rownames(out[[1]])
    unlist(lapply(out, function(v) {
      all_identical(first_rownames, rownames(v))}))
  })

  return(out)
}

#' @export
calc_elecreg_index <- function(v) {
  change <- diff(v)
  change[change == -1] <- 1
  cumsum(c(1, change))
}

#' @export
utable_join_elecreg_index <- function(utable, elecreg_cy) {
  if ("historical_date" %in% names(elecreg_cy))
    elecreg_cy %<>% dplyr::select(-historical_date)
  dplyr::left_join(utable, elecreg_cy, by = c("country_id", "year")) %>%
    dplyr::group_by(gap_idx) %>%
    dplyr::mutate(elecreg_idx = calc_elecreg_index(v2x_elecreg)) %>%
    dplyr::group_by(gap_idx, elecreg_idx) %>%
    dplyr::mutate(combined_idx = dplyr::cur_group_id())
}

#' @export
front_filling_els_variables <- function(m, utable, elecreg_cy, elecreg_cd, country, party = FALSE) {
  join_cols <- c("country_text_id", "year")
  elecreg_cd %<>% dplyr::left_join(dplyr::select(country, country_id, country_text_id), by = "country_id")
  df <- data.frame(country_text_id = rownames(m) %>% get_text_id(party),
                   historical_date = rownames(m) %>% get_date(party)) %>%
    dplyr::left_join(dplyr::select(elecreg_cd, country_text_id, historical_date,
                                   v2x_elecreg_cd = v2x_elecreg),
                     by = c("country_text_id", "historical_date"))
  utable_merged <- utable_join_elecreg_index(utable, elecreg_cy) %>%
    dplyr::select(-historical_date)

  df %<>%
    dplyr::mutate(year = to_year(historical_date)) %>%
    dplyr::left_join(utable_merged, by = join_cols)
  nn <- colnames(m)
  rr <- rownames(m)
  m_df <- as.data.frame(m) %>%
    dplyr::bind_cols(dplyr::select(df, country_text_id, historical_date, year, gap_idx,
                                   combined_idx, v2x_elecreg, v2x_elecreg_cd))

  fu <- function(subdf) {
    # print(distinct(subdf, country_text_id, historical_date))
    bool <- is.na(subdf[, 1])
    # If first value is not NA return subdf
    if (!bool[1])
      return(subdf)
    first_non_na <- which(!bool)
    if (length(first_non_na) == 0)
      return(subdf)
    # First matching row with data
    first_non_na <- first_non_na[1]
    # Is v2x_elecreg 1 ?
    # We don't want to front fill if there is a case with elecreg 0
    # (e.g. Germany 1949)
    if (all(subdf$v2x_elecreg[1:(first_non_na - 1)] == 1) &
        ((!any(subdf$v2x_elecreg_cd[1:(first_non_na - 1)] == 0)) %||% FALSE)) {
      subdf[1:(first_non_na - 1), ] <-
        do.call("rbind", replicate(first_non_na - 1,
                                   subdf[first_non_na, ],
                                   simplify = FALSE))
      info(nn[1] %^% ": Front-filled " %^% rownames(subdf[1:(first_non_na - 1), ]) %^% " from " %^% rownames(subdf[first_non_na, ]))
    }
    return(subdf)
  }

  m_df_done <- split.data.frame(m_df, df$gap_idx) %>%
    lapply(., fu) %>%
    dplyr::bind_rows(.)
  rr <- paste0(m_df_done$country_text_id, " ", m_df_done$historical_date)
  m_df_done %<>%
    dplyr::select(-country_text_id, -historical_date, -year, -gap_idx,
                  -combined_idx, -v2x_elecreg, -v2x_elecreg_cd) %>%
    data.matrix(.)
  # rownames(m_df_done) <- rr
  colnames(m_df_done) <- nn
  m_df_done <- m_df_done[rownames(m), ]

  # Check that non-NA observations are identical!
  bool <- !is.na(m[, 1])
  stopifnot(identical(m[bool, ], m_df_done[bool, ]))

  return(m_df_done)
}

#' @export
get_varname <- function(id, db) {
  dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::filter(task_id == id) %>%
    dplyr::select(question_name) %>%
    dplyr::collect(n = Inf) %$% question_name
}

#' @export
get_outdir <- function(id, db) {
  dplyr::tbl(db, dbplyr::in_schema("pipe", "modules")) %>%
    dplyr::filter(module_id == id) %>%
    dplyr::pull(outdir)
}

#' @export
create_outfile <- function(id, ROOT, db) {
  outdir <- dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::filter(task_id == id) %>%
    dplyr::pull(module_id) %>%
    get_outdir(., db)

  varname <- get_varname(id, db)
  return(file.path(ROOT, outdir, paste0(varname, "_", add_zeroes(id), ".rds")))
}

#' @export
create_outfile_local <- function(ids, tasks, modules, ROOT) {
  df <- dplyr::left_join(tasks, modules, by = c("module_id", "module_name")) %>%
    dplyr::filter(task_id %in% ids)
  formatted_ids <- vapply(ids, add_zeroes, FUN.VALUE = character(1))
  outfile <-
    file.path(ROOT, df$outdir,
              paste0(df$question_name, "_", formatted_ids, ".rds"))
  return(outfile)
}


#' @export
add_zeroes <- function(id) {
  n_rep <- 6 - {nchar(as.character(id))}
  zeroes <- Reduce("paste0",{rep(0, n_rep)})
  zeroes %^% id
}

#' @export
find_dep_files <- function(id, db, check_dep_status = TRUE) {

  varname <- get_varname(id, db)

  df <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::collect(n = Inf) %>%
    as.data.frame(stringsAsFactors = F)
  dependencies <- strsplit(df$deps[df$task_id == id], split = ",") %>%
    unlist %>%
    as.integer
  df %<>%
    dplyr::filter(task_id %in% dependencies) %>%
    dplyr::select(task_id, question_name, status, module_name)
  # stop if any dependencies are not done yet
  if (any(df$status != "done") & check_dep_status) {
    update_task_status_no_timestamp(status = "waiting", db = db)
    info("Some dependencies are not done yet!")
    quit(save = "no", status = 0)
  }
  # Do any questions show up twice? e.g. for coder_table?
  double_que =
    ifelse(length(unique(df$question_name)) != nrow(df), TRUE, FALSE)

  ll <- list()
  for (i in 1:nrow(df)) {
    if (!double_que) {
      ll[[df$question_name[i]]] <-
        read_file(find_dep_file_by_task(df$task_id[i], varname))
    } else {
      ll[[df$question_name[i] %^% "_" %^% df$module_name[i]]] <-
        read_file(find_dep_file_by_task(df$task_id[i], varname))
    }
  }
  ll
}


#' @export
try_find_dep_files <- function(id, db, lev) {

  varname <- get_varname(id, db)
  # load only cd or cy and then remove object to save memory!
  df <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::collect(n = Inf) %>%
    as.data.frame(stringsAsFactors = F)
  dependencies <- strsplit(df$deps[df$task_id == id], split = ",") %>%
    unlist %>%
    as.integer
  df %<>%
    dplyr::filter(task_id %in% dependencies) %>%
    dplyr::select(task_id, question_name, status, module_name)

  ll <- list()
  for (i in 1:nrow(df)) {
    tryCatch({
      ll[[df$question_name[i] %^% "_" %^% df$module_name[i]]] <-
        read_file(find_dep_file_by_task(df$task_id[i], varname))
    }, error = function(err){
      print("failed to load task file: " %^%
              df$question_name[i] %^% "_" %^% df$module_name[i])
    }, warning = function(war){})
  }
  ll
}

#' @export
find_dep_file_by_task <- function(id, varname = "") {
  ll <- list.files(Sys.getenv("ROOT_DIR"),
                   full.names = T,
                   recursive = T,
                   pattern = add_zeroes(id))

  if (length(ll) == 0)
    stop("Did not find dependency file for task_id " %^% id)

  if (length(ll) > 1) {
    ll <- ll[grepl(varname, ll)]
    if (length(ll) != 1)
      stop("Several files found, dont know which one to use.")
  }

  stopifnot(length(ll) == 1)

  ll
}
#' Run individual task
#'
#' @export
run_task <- function(id, module_name, question_name, cmd = "Rscript", script,
                     docopt = "", export = NA_character_, open_blas_single_threaded = TRUE) {
  if (is.na(id) | id == "NA") {
    stop("Wrong run_task call!")
  }

  # Environment variables for pipe.logs table
  envir_vars <- paste0(unlist(Map(function(var, value) {
    paste0("export ", var, "=", value, ";")
  }, var = c("TASK_ID", "MODULE_NAME", "VARIABLE"),
  c(id, module_name, question_name))), collapse = "")

  if (!is.na(export) && grepl("=", export) && grepl(";$", export)) {
    envir_vars <- paste(envir_vars, export, sep = "export ")
  } else if (!is.na(export)) {
    warning("Check export argument: does it have ; at the end? Does it contain =?")
  }

  if (open_blas_single_threaded) {
    envir_vars <- paste0(envir_vars, "export OPENBLAS_NUM_THREADS=1;")
  }

  # The guy who answered is awesome!
  # https://stackoverflow.com/questions/64678404/how-to-use-the-following-command-from-r-echo-pipestatus1
  end_string <- '2>&1 | tee /dev/tty | xargs -d "\n" log_postgres; echo "${pipestatus[1]}"'

  if (isTRUE(docopt == "" | is.na(docopt))) {
    func_args <- paste(cmd, script, end_string)
  } else {
    func_args <- paste(cmd, script, docopt, end_string)
  }
  func_args <- shQuote(func_args)
  system2("zsh", args = c('-c', func_args), env = envir_vars, stderr = TRUE, stdout = TRUE)
}

#' Determine which tasks need to be run
#'
#' @export
make <- function(ids,
                 deps = T,
                 force = F,
                 simulate = F,
                 n_cores = 4,
                 db) {

  make_tbl <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::collect(n = Inf)
  modules <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "modules")) %>%
    dplyr::collect(n = Inf)
  make_tbl <- dplyr::left_join(make_tbl,
                               modules,
                               by = c("module_id", "module_name"))

  # Remove or find dependencies
  if (!deps) {
    tasks <- dplyr::filter(make_tbl, task_id %in% ids)
  } else {
    info("Tracing dependencies...")
    tasks <- trace_deps(ids, make_tbl)
  }

  # What if we depend on a task that is locked or waiting?
  # We need to remove that branch and print a message
  info("Checking if tasks have unfinished dependencies...")
  # This function needs to be sped up using something like memoization
  # We shouldn't have to trace again and again the same tasks / branches.
  bool <- lapply(1:nrow(tasks), function(i) {
    deps <- trace_deps(tasks$task_id[i], make_tbl)
    if (nrow(deps) == 1) return(TRUE)
    # remove own value from deps
    deps <- dplyr::filter(deps, !task_id %in% tasks$task_id[i])

    ### Now that we're in a loop check for timestamps as well.
    current_timestamp <- tasks$ts[i]
    if (!is.na(current_timestamp) &
        (!tasks$status[i] %in% c("not_started", "recalc", "waiting"))) {
      if (any(deps$ts > current_timestamp) %||% FALSE)
        stop("Error, Timestamp issue, run check_timestamps(db)")
    }
    ### End check for timestamps


    # We still want to run if a dependency is set to waiting, but is in ids
    deps <- dplyr::filter(deps, !task_id %in% tasks$task_id)

    if (any(deps$status != "done")) {
      return(FALSE)
    }
    return(TRUE)
  }) %>% unlist

  if (any(!bool)) {
    info("These tasks are waiting: " %^% tasks$task_id[!bool])
    # Set waiting tasks to waiting and remove them from the tasks to do
    for (i in tasks$task_id[!bool]) {
      update_task_status_no_timestamp(
        status = "waiting",
        id = i,
        db = db)
    }

    tasks <- tasks[bool, ]
  }

  # Unless we force, we can remove those that are done
  if (!force) {
    tasks %<>% dplyr::filter(status != "done")
  }

  # Do not touch locked rows (change manually in postgres to get around this)
  tasks %<>% dplyr::filter(lock == FALSE)

  if (nrow(tasks) == 0L) {
    info("No tasks to do")
    return(NULL)
  }

  # For simulation just return table
  if (simulate) return(tasks)

  # In other cases call run_make to execute the tasks
  run_make(tasks, n_cores = n_cores, db)


}

#' Determine order of tasks to run and pass on to run_task function
#'
#'@export
run_make <- function (tasks, n_cores = 1, db) {
  # run all jobs whose id is not in deps
  # remove from table,
  # run all jobs whose id is not in deps
  # repeat
  counter <- 1

  while (T) {
    info("Loop of independent tasks: " %^% counter)

    subtasks <- tasks
    run_vars <- numeric(0)
    # which rows do not have dependencies in the same table?
    all_ids <- tasks[["task_id"]]

    for (i in all_ids) {
      rowi <- tasks[tasks$task_id == i, ]
      dependencies <-
        strsplit(rowi$deps, split = ",") %>%
        unlist %>%
        unique

      if (any(dependencies %in% all_ids)) {
        next
      }

      run_vars <- c(run_vars, i)
    }

    # run these in parallel:
    subtasks %<>% dplyr::filter(task_id %in% run_vars)
    subtasks_parallel <-
      subtasks %>%
      dplyr::filter(is.na(ncores) | ncores == 1) %>%
      dplyr::arrange(task_id)
    subtasks_no_parallel <-
      subtasks %>%
      dplyr::filter(!is.na(ncores) & ncores != 1) %>%
      dplyr::arrange(task_id)


    if (nrow(subtasks_parallel) > 0) {
      info("Parallel run tasks:")
      print(subtasks_parallel)
      parallel::mclapply(1:nrow(subtasks_parallel), function (i) {
        w <- subtasks_parallel[i, ]
        delete_logs(w$task_id)
        run_task(id = w$task_id,
                 module_name = w$module_name,
                 question_name = w$question_name,
                 cmd = w$cmd,
                 script = w$script,
                 docopt = w$docopt,
                 export = w$export)
      }, mc.preschedule = F, mc.cores = n_cores) %>% invisible
    }



    # These scripts have parallelization within the script
    if (nrow(subtasks_no_parallel) > 0) {
      info("Sequentially run tasks:")
      print(subtasks_no_parallel)
      for (i in 1:nrow(subtasks_no_parallel)) {
        w <- subtasks_no_parallel[i, ]
        delete_logs(w$task_id)
        run_task(id = w$task_id,
                 module_name = w$module_name,
                 question_name = w$question_name,
                 cmd = w$cmd,
                 script = w$script,
                 docopt = w$docopt,
                 export = w$export)
      }
    }

    # If individual tasks did not complete then remove dependent tasks
    # for next iterations
    bad_tasks <-
      dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
      dplyr::filter(task_id %in% run_vars) %>%
      dplyr::filter(status != "done") %>%
      dplyr::select(task_id) %>%
      dplyr::collect(n = Inf)


    if (nrow(bad_tasks) > 0) {
      # Print information about failed tasks
      info("Failed or hpc-waiting tasks: " %^% bad_tasks$task_id)

      # Any tasks in tasks dependent on this?
      remove_ids <-
        lapply(bad_tasks$task_id, function(i) {
          find_deps_reverse_rec(i, tasks)
        }) %>% unlist %>% unique
      if (length(remove_ids) > 0) {
        info("Removing these tasks because dependency did not finish:" %^% remove_ids)
        for (i in remove_ids) {
          update_task_status_no_timestamp(
            status = "waiting",
            id = i,
            db = db)
        }
      }
    } else {remove_ids <- NULL}


    # Remove tasks that were run
    tasks %<>% dplyr::filter(!task_id %in% c(run_vars, remove_ids))

    if (nrow(tasks) == 0)
      break
    counter <- counter + 1
  }


}

#' @export
delete_logs <- function(id, db_log = vbase::pg_connect(Sys.getenv("DS_VERSION"))) {
  DBI::dbGetQuery(db_log,
                  "DELETE FROM pipe.logs WHERE task_id=" %^% id %^% ";") %>% invisible
  DBI::dbDisconnect(db_log) %>% invisible
}

#' @export
delete_coder_question <- function(question_id, db) {
  DBI::dbGetQuery(db,
                  "DELETE FROM pipe.coder_table WHERE question_id=" %^% question_id %^% ";")
}

#' @export
get_ncores <- function(id, db) {
  mod_id <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::filter(task_id == as.numeric(id)) %>%
    dplyr::collect(n = Inf) %$%
    module_id
  ncpus <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "modules")) %>%
    dplyr::filter(module_id == mod_id) %>%
    dplyr::collect(n = Inf) %$%
    ncores
  ncpus
}


#' @export
find_deps_rec <- function(idx, make_tbl) {
  if (is.null(idx)) return(NULL)
  d <-
    make_tbl %>%
    dplyr::filter(task_id == idx) %$%
    deps %>%
    strsplit(., ",") %>%
    unlist
  if (length(d) == 1) if(unique(d) == 0) return(0)
  c(d, lapply(d, function(a) {find_deps_rec(a, make_tbl)}) %>% unlist)
}

#' @export
trace_deps <- function(ids, make_tbl) {
  # keep only ids and dependencies
  keep <- ids
  for (id in ids) {
    deps <- find_deps_rec(id, make_tbl)
    keep <- c(keep, deps)
  }
  keep <- unique(keep)
  make_tbl %>% dplyr::filter(task_id %in% keep)
}

#' @export
trace_reverse_deps <- function(ids, make_tbl) {
  # keep only ids and dependencies
  keep <- ids
  for (id in ids) {
    deps <- find_deps_reverse_rec(id, make_tbl)
    keep <- c(keep, deps)
  }
  keep <- unique(keep)
  make_tbl %>%
    dplyr::filter(task_id %in% keep) %>%
    dplyr::arrange(task_id)
}

#' @export
find_deps_reverse_rec <- function(idx, make_tbl) {
  if (is.null(idx)) return(NULL)
  bool <-
    grepl("^" %^% idx %^% "$", make_tbl$deps) |
    grepl("^" %^% idx %^% "[,]", make_tbl$deps) |
    grepl("[,]" %^% idx %^% "[,]", make_tbl$deps) |
    grepl("[,]" %^% idx %^% "$", make_tbl$deps)
  if (sum(bool) == 0) return(NULL)
  d <-
    make_tbl %>%
    dplyr::filter(bool) %$% task_id
  c(d, lapply(d, function(a) {find_deps_reverse_rec(a, make_tbl)}) %>% unlist)
}



#' @export
check_timestamps <- function(db) {

  anyChange <- TRUE
  nn <- 1
  while (anyChange) {
    info(nn)
    loop_table <- DBI::dbGetQuery(db, "select * from pipe.make;") %>%
      dplyr::filter(!is.na(ts))

    dep_table <- loop_table %>%
      tidyr::unnest(deps = strsplit(deps, ",")) %>%
      dplyr::select(task_id, deps, task_ts = ts, task_status = status) %>%
      dplyr::mutate(deps = as.numeric(deps)) %>%
      dplyr::left_join(select(loop_table, deps = task_id, dep_ts = ts, dep_status = status),
                       by = "deps") %>%
      dplyr::filter(deps != 0) %>%
      dplyr::rename(dep_id = deps)

    bool <- (dep_table$task_ts < dep_table$dep_ts |
               (dep_table$dep_status %in% c("recalc", "waiting"))) &
      (!dep_table$task_status %in% c("recalc", "waiting"))
    if (anyNA(bool)) {
      info("Some tasks do not track to dependency 0!")
      dep_table %>%
        dplyr::filter(is.na(bool)) %>%
        dplyr::select(task_id) %>%
        print(.)
    }


    if (any(bool)) {
      anyChange <- TRUE
    } else {
      anyChange <- FALSE
      info("done with checks!")
    }

    mismatch_id <-
      dep_table$task_id[bool] %>%
      unique

    if (length(mismatch_id) > 0) {
      for (i in 1:length(mismatch_id)) {
        print("Timestamp mismatch detected for TASK_ID: " %^% mismatch_id[i])
        update_task_status_no_timestamp(status = "recalc",
                                        id = mismatch_id[i],
                                        db = db)
      }
    } else {
      info("All timestamps are now fine.")
    }

    nn <- nn + 1
  }
}

#' @export
find_latest_dep <- function(name, tasks) {

  # find latest step that is still connected to deps = 0.
  name_tasks <- tasks %>% dplyr::filter(question_name == name)
  if (nrow(name_tasks) == 0)
    stop("There is no task for this question!: " %^% name)

  if (nrow(name_tasks) == 1)
    return(name_tasks$task_id)

  all_deps <-
    trace_deps(name_tasks$task_id, tasks)$deps %>%
    strsplit(split = ",") %>% unlist %>% as.numeric %>% unique

  # find a task in name_tasks that is connected to 0
  # and no other task depends on it!
  last_id <- numeric(0)
  for (i in 1:nrow(name_tasks)) {
    deps <- trace_deps(name_tasks$task_id[i], tasks)
    deps <- deps[deps$task_id != name_tasks$task_id[i], ]
    # if (!0 %in% deps$deps)
    #    next

    # No tasks depends on this one:
    if (!name_tasks$task_id[i] %in% all_deps) {
      last_id <- c(last_id, name_tasks$task_id[i])
    }
  }

  # If we catch more than one take the larger task_id
  if (length(last_id) > 1)
    last_id <- max(last_id)

  if (length(last_id) == 0) {
    info("Did not find latest dependency for " %^% name)
    return(NA_real_)
  }
  last_id
}


#' @export
find_latest_dep_vec <- function(many_names, tasks) {
  lapply(many_names, function(na) {
    find_latest_dep(na, tasks)
  }) %>% unlist
}

#' Get the task_id for a new task
#'
#' @param var_name A character vector; it can be of any length.
#'
#' @param conn A DBI connection to PostgreSQL database that has a schema called "pipe".
#'
#' @export
make_id <- function(var_name, conn) {
  prev_id <- dplyr::tbl(conn, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::summarise(task_id_max = max(task_id, na.rm = TRUE)) %>%
    dplyr::pull(task_id_max)
  id <- seq({prev_id + 1}, {prev_id + length(var_name)}, 1)
  return(id)
}

#' Create modules for Make table in PostgreSQL
#'
#' @param mod_name A character vector of module names that need to be added for a variable.
#'
#' @param var_name A character vector of length 1 that specifies the variable for which the module is added.
#'
#' @param make_df A data.frame with all tasks.
#'
#' @param conn A PostgreSQL connection.
#'
#' @examples
#' # !!!Don't Run!!!
#' # Don't run this function in parallel, NEVER EVER.
#' # Otherwise, everything is going to be screwed up!
#' # Below, you see a typical use of the function.
#'
#' # library(vutils)
#' # conn <- pg_connect("v902")
#' # vars <- c("v2eldonate", "v2peasbsoc", "v2psprbrch", "v2exdfcbhs")
#' # mode_name <- c("download_var", "cleaning", "clean_all", "cont_hist_merge")
#' # mk <- tbl(conn, dbplyr::in_schema("pipe", "make")) %>% collect(n = Inf)
#'
#' # lapply(vars, function(var) {
#'    # make_module(mode_name, var, mk, conn) %>%
#'    # mutate(docopt = NA_character_,
#'    #     file = paste0(var, ".rds"),
#'    #     tbl = NA_character_,
#'    #     version = "v902",
#'    #     ts = NA) %>%
#'    # pg_append_table(., "pipe.make", conn)
#' # })
#'
#' @export
make_module <- function(mod_name, var_name, make_df, conn) {

  mod_id <- dplyr::tbl(conn, dbplyr::in_schema("pipe", "modules")) %>%
    dplyr::filter(module_name %in% mod_name) %>%
    dplyr::collect %>%
    .[match(mod_name, .[["module_name"]]),] %>%
    dplyr::pull(module_id)

  deps <- sapply(1:length(mod_name), function(count) {
    if(mod_name[count] == "download_var") {
      as.character(0)
    } else if(mod_name[count] == mod_name[1] && !any(mod_name %in% "download_var")) {
      as.character(find_latest_dep(var_name, make_df))
    } else {
      as.character(id[count] - 1)
    }
  })

  df_up <- data.frame(
    module_id = mod_id,
    module_name = mod_name,
    question_name = var_name,
    deps = deps,
    status = "not_started",
    lock = FALSE,
    stringsAsFactors = FALSE
  )

  return(df_up)
}

#' @export
check_direct_deps <- function(id = Sys.getenv("TASK_ID"), db) {

  df <-
    dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::collect(n = Inf) %>%
    as.data.frame(stringsAsFactors = F)
  dependencies <- strsplit(df$deps[df$task_id == id], split = ",") %>%
    unlist %>%
    as.integer
  df %<>%
    dplyr::filter(task_id %in% dependencies) %>%
    dplyr::select(task_id, question_name, status, module_name)
  # stop if any dependencies are not done yet
  if (any(df$status != "done")) {
    update_task_status_no_timestamp(status = "waiting", db = db)
    info("Some dependencies are not done yet!")
    quit(save = "no", status = 0)
  }
  info("All deps are fine...")
}


#' @export
stid <- function(id) {
  Sys.setenv("TASK_ID" = as.character(id))
}

#' @export
load_task_file <- function(variable, module, ROOT = Sys.getenv("ROOT_DIR"), db = db) {
  stopifnot(ROOT != "")
  tasks <- load_tasks(db)
  tasks %>% dplyr::filter(module_name == module, question_name == variable) %$%
    task_id %>% vutils::find_dep_file_by_task(.) %>% vbase::read_file(.)
}

#' @export
load_tasks <- function(db) {
  dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
    dplyr::collect(n = Inf)
}

#' @export
get_globals <- function() {
  # Having both pointers is a temporary solution
  # We want to use DB in the future
  db <<- vbase::pg_connect(Sys.getenv("DS_VERSION"))
  DB <<- db
  # If DEBUG is TRUE use first task_id per module in interactive mode
  if (isTRUE(as.logical(Sys.getenv("DEBUG"))) & interactive() & Sys.getenv("TASK_ID") == "") {
    tt <- dplyr::tbl(db, dbplyr::in_schema("pipe", "make")) %>%
      dplyr::collect(n = Inf) %>%
      dplyr::filter(module_name == Sys.getenv("MODULE_NAME")) %>%
      dplyr::arrange(task_id) %$%
      dplyr::first(task_id)
    Sys.setenv(TASK_ID = tt)
    warn("SETTING TASK_ID FROM DEBUG MODE!!!")
  }

  ROOT <<- Sys.getenv("ROOT_DIR")
  OUTFILE <<- vutils::create_outfile(id = Sys.getenv("TASK_ID"),
                                     ROOT = ROOT,
                                     db = db)
  VARNAME <<- vutils::get_varname(Sys.getenv("TASK_ID"), db)
  TASK_ID <<- Sys.getenv("TASK_ID")
  MODULE_NAME <<- Sys.getenv("MODULE_NAME")
  print(vbase::session_info())
}

#' @export
no_test <- function() {
  bool <- !isTRUE(as.logical(Sys.getenv("UNIT_TESTS")))
  if (!bool) {
    db <<- vbase::pg_connect(Sys.getenv("DS_VERSION"))
    DB <<- db
  }
  return(bool)
}

#' @export
set_env <- function(...) {
  if(interactive())
    Sys.setenv(...)
}
#' @export
clean_by_utable <- function(x, utable) {UseMethod("clean_by_utable")}

#' @export
clean_by_utable.default <- function(x, utable) {
  stop("No defined method for this object!")
}

#' @export
clean_by_utable.data.frame <- function(x, utable) {
  stopifnot(c("year", "country_id") %in% names(x))
  dplyr::inner_join(x, select(utable, country_id, year),
                    by = c("country_id", "year")) %>%
    as.data.frame(stringsAsFactors = FALSE)
}

#' @export
clean_by_utable.matrix <- function(x, utable) {
  df <- data.frame(
    country_text_id = substr(rownames(x), 1, 3),
    historical_date = substr(rownames(x), 5, 8) %^% "-12-31",
    stringsAsFactors = F) %>%
    dplyr::left_join(
      dplyr::select(utable, country_text_id,
                    historical_date, project),
      by = c("country_text_id", "historical_date"))
  bool <- !is.na(df$project)
  x[bool, ]
}

#' @export
check_utable <- function(df, utable) {
  stopifnot(c("year", "country_id") %in% names(df))
  dplyr::anti_join(df, select(utable, country_id, year),
                   by = c("country_id", "year")) %>%
    nrow %>% . == 0
}
#' Question tag root
#'
#' Given a vector of question names, \code{get_root} returns the
#' original, non-transformed corresponding tags. Note, ordinalized
#' versions of the HLIs are considered separate question tag, since
#' they have alternative entries in the codebook.
#'
#' @param x CharacterVector of question names. For example, the column
#'     names from the final V-Dem DS.
#'
#' @section Warning: Here be dragons. We will only transform V-Dem
#'     variable tags, meaning that we'll attempt to match \code{v\\d}
#'     or \code{e_v\\d}, while always excluding the direct democracy
#'     variables (v2dd* or v2xdd*) since we never create separate
#'     versions of those.
#'
#' @examples
#' get_root(c("v2clacfree", "v2clacfree_osp", "v2x_freexp_codehigh"))
#'
#' @export
get_root <- function(x) {


  gsub("^(e_v2x|v\\d)(.*?)" %^% paste(c("(_osp$", "_osp_codelow$",
                                        "_osp_codehigh$", "_osp_sd$",
                                        "_ord$", "_ord_codelow$",
                                        "_ord_codehigh$",
                                        "_mean$",
                                        "_nr$",
                                        "_codelow$", "_codehigh$", "_sd$)"), collapse = "|"),
       "\\1\\2", x, perl = FALSE) %>%
    gsub("^(e_v2x.*?)_\\dC$", "\\1_3C", .) %>%
    gsub("gapstart\\d$", "gapstart", .) %>%
    gsub("gapend\\d$", "gapend", .)
}

#' Historical/Contemporary questions
#'
#' Check whether a given question tag is historical (v3) or
#' contemporary (v2).
#'
#' @param x CharacterVector of question tags
#'
#' @examples
#' is.contemp(c("v2clacfree", "v3clacfree"))
#' is.hist(c("v2csreprss", "v3csreprss"))
#'
#' @export
is.contemp <- function(x) {
  substring(x, 1, 2) == "v2"
}

#' @rdname is.contemp
#' @export
is.hist <- function(x) {
  substring(x, 1, 2) == "v3"
}

#' Check if a variable exists for both contemporary and historical
#'
#' \code{is.shared_tag} takes a vector of variable tag names and returns
#' a logical vector indicating which variables exist in both
#' historical and contemporary.
#'
#' @param tags CharacterVector of v2/v3 tag names.
#' @param ttable Translation table listing all contemporary (v2) and
#'     historical (v3) variable tag names (typically our
#'     question_table).
#'
#' @section Warning: \code{is.shared_tag} works only with v2/v3 tag
#'     names. So older variable names lacking the necessary prefix
#'     will always return FALSE, which is actually what we want
#'     because they only exist in the deprecated contemporary surveys.
#'
#' @examples
#' vars <- c("v2clacfree", "v3clacfree", "v3elage", "v2elpdcamp")
#' ttable <- data.frame(name = vars, stringsAsFactors = FALSE)
#'
#' is.shared_tag(vars, ttable)
#'
#' @return LogicalVector
#'
#'@export
is.shared_tag <- function(tags, ttable) {
  if (!"name" %in% colnames(ttable))
    stop("Missing name column in ttable")

  if (any(!tags %in% ttable$name))
    stop("Missing values in ttable from " %^% deparse(substitute(v)))

  roots <- substring(tags, 3)
  ifelse(("v3" %^% roots) %in% ttable$name & ("v2" %^% roots) %in% ttable$name, T, F)
}

#' Get survey from question tag
#'
#' Given a vector of question tags, \code{get_survey} returns the
#' two letter survey abbreviation for A*, A, B, and C-variables
#'
#' @param x CharacterVector of question tags.
#'
#' @examples
#' get_survey(c("v2clacfree", "v2dlcountr"))
#'
#' @export
get_survey <- function(x) {

  if (any(!grepl("^v\\d[a-z]+$", x)))
    stop("Invalid input, expected an A*, A, B, C tag name.", call. = F)

  substr(x, 3, 4)
}
replace_version <- function(datarelease, options, replacements) {
  stopifnot(length(options) == length(replacements),
            all(!is.na(options)), all(!is.na(replacements)))
  for (i in seq_along(options)) {
    datarelease <- gsub(options[i], replacements[i], datarelease)
  }
  return(datarelease)
}

#' Convert regular V-Dem data release version to V-Party version
#'
#' Replace original data releases with V-Party releases
#'
#' @param datarelease Vector (character) with data releases information.
#' @param options Vector (character or numeric) of regular data releases in which V-Party data is released as well.
#'
#' @return Character vector of \code{datarelease} length with replacements.
#'
#' @examples
#' \dontrun{
#'VPARTY_RELEASES <- unlist(strsplit("10.12.14", "[.]"))
#'datarelease <- c("10-14.",
#'	"10-14. Available upon request, subject to review and approval",
#'	"10-14.", "14.", "11.", "9-12", "9-10.")
#'convert_version(datarelease, VPARTY_RELEASES)
#'}
#'
#' @export
convert_version <- function(datarelease, vparty_releases) {
  stopifnot(!all(is.null(vparty_releases)))
  stopifnot(class(datarelease) %in% "character")
  stopifnot(class(vparty_releases) %in% c("character", "numeric"))
  opts <- sort(as.numeric(vparty_releases))
  val1 <- 1
  repl <- val1:length(unique(opts))

  datarelease_repl <- vutils:::replace_version(datarelease, options = opts, replacements = repl)

  opts_over <- gsub("(^\\d{1,2}[-]?\\d{1,2}?)(\\. .*)", "\\1", datarelease) %>%
    gsub("\\.$", "", x = .) %>%
    unique() %>%
    strsplit("-") %>%
    lapply(function(x) x[[1]]) %>%
    unlist() %>%
    as.numeric() %>%
    unique() %>%
    .[. < as.numeric(opts[1])] %>%
    paste0("-")

  repl_over <- paste0(rep(val1, length(opts_over)), "-")

  datarelease_out <- vutils:::replace_version(datarelease_repl, options = opts_over, replacements = repl_over)

  if (any(grepl("^1-1.", datarelease_out))) {
    datarelease_out <- gsub("^1-1.", "1.", datarelease_out)
  }

  return(datarelease_out)
}
#' vutils
#'
#' Internal V-Dem Functions
#'
#' @docType package
#' @author Joshua Krusell <joshua.krusell@v-dem.net>
#' @useDynLib vutils
#' @importFrom Rcpp sourceCpp
#' @name vutils
if (getRversion() >= "2.15.1")
  utils::globalVariables(".")

NULL
# We want to know when loading pkg if:
#   1. Suggested packages are not installed. We avoid Imports to
#      minimize dependences when installing on an HPC.
#   2. A new `vutils` version is available
.onAttach <- function(libname, pkgname) {
  if (!interactive())
    return(NULL)

  parallel::mcparallel({
    dcf <- utils::packageDescription(pkgname)
    pkg_repo <- dcf$Repository
    pkg_version <- dcf$Version
    pkg_suggests <- unlist(strsplit(dcf$Suggests, ","))

    # Start by checking suggested packages
    b <- vapply(pkg_suggests, function(pkg) {
      name <- trimws(pkg)
      length(find.package(name, quiet = T)) == 0
    }, logical(1))

    not_installed <- pkg_suggests[b]

    if (length(not_installed) > 0) {
      recommended <- paste(not_installed, collapse = ", ")
      packageStartupMessage(sprintf("The following packages are recommended: %s", recommended))
    }

    # Now check if there are any updates available
    repos <- getOption("repos")
    if (!pkg_repo %in% names(repos)) {
      warning(sprintf("Unable to find repository: %s. Defaulting to CRAN.", pkg_repo))
      pkg_repo <- "CRAN"
    }

    cran_url <- repos[names(repos) == pkg_repo]

    # Default CRAN repo hasn't been set
    if (cran_url == "@CRAN@")
      return(NULL)

    contriburl <- utils::contrib.url(cran_url)

    cran_version <- NULL
    if(RCurl::url.exists(contriburl, timeout = 4)) {
      Sys.sleep(3)
      try(cran_version <- utils::available.packages(contriburl = contriburl)[pkgname, "Version"],
          silent = T)
    }
    if (is.null(cran_version)) {
      packageStartupMessage(sprintf("Unable to determine remote version of %s", pkgname))
    } else {
      if (utils::compareVersion(pkg_version, cran_version) < 0)
        packageStartupMessage(sprintf("[%s] Update available: %s. Currently installed: %s",
                                      pkgname, cran_version, pkg_version))
      else
        packageStartupMessage(sprintf("[%s] is up to date. CRAN version: %s. Currently installed: %s",
                                      pkgname, cran_version, pkg_version))
    }

    # auto update if there is a newer version?
    # update.packages(repos="http://my.local.server/R", ask=FALSE)
  })

}

use_r("test")
load_all()
exists("test", where = globalenv(), inherits = FALSE)
check()
use_mit_license()
check()
install()
library(vutils)
